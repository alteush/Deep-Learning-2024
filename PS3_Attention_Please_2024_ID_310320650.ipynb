{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alteush/Deep-Learning-2024/blob/main/PS3_Attention_Please_2024_ID_310320650.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOpGoE2T-YXS"
      },
      "source": [
        "# Neural Machine Translation with Attention\n",
        "\n",
        "Advanced Learning Fall 2024.   \n",
        "Last updated: 2025-01-12\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpJdYve9cZa6"
      },
      "source": [
        "For SUBMISSION:   \n",
        "\n",
        "Please upload the complete and executed `ipynb` to your git repository. Verify that all of your output can be viewed directly from github, and provide a link to that git file below.\n",
        "\n",
        "~~~\n",
        "STUDENT ID: 310320650\n",
        "~~~\n",
        "\n",
        "~~~\n",
        "STUDENT GIT LINK: https://github.com/alteush/Deep-Learning-2024/tree/main/Problem%20Set%203\n",
        "~~~\n",
        "In Addition, don't forget to add your ID to the files, and upload to moodle the html version:    \n",
        "  \n",
        "`PS3_Attention_2024_ID_310320650.html`   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eecp2PAf7qJq"
      },
      "source": [
        "In this problem set we are going to jump into the depths of `seq2seq` and `attention` and build a couple of PyTorch translation mechanisms with some  twists.     \n",
        "\n",
        "\n",
        "*   Part 1 consists of a somewhat unorthodox `seq2seq` model for simple arithmetics\n",
        "*   Part 2 consists of an `seq2seq - attention` language translation model. We will use it for Hebrew and English.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VpUCez9gOZn"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajNDsL5HlZN6"
      },
      "source": [
        "A **seq2seq** model (sequence-to-sequence model) is a type of neural network designed specifically to handle sequences of data. The model converts input sequences into other sequences of data. This makes them particularly useful for tasks involving language, where the input and output are naturally sequences of words.\n",
        "\n",
        "Here's a breakdown of how `seq2seq` models work:\n",
        "\n",
        "* The encoder takes the input sequence, like a sentence in English, and processes it to capture its meaning and context.\n",
        "\n",
        "* information is then passed to the decoder, which uses it to generate the output sequence, like a translation in French.\n",
        "\n",
        "* Attention mechanism (optional): Some `seq2seq` models also incorporate an attention mechanism. This allows the decoder to focus on specific parts of the input sequence that are most relevant to generating the next element in the output sequence.\n",
        "\n",
        "`seq2seq` models are used in many natural language processing (NLP) tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbUDn4FObol7"
      },
      "source": [
        "imports: (feel free to add)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "5g0nEd5o1Q5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crTe33wcD_Eg"
      },
      "outputs": [],
      "source": [
        "# from __future__ import unicode_literals, print_function, division\n",
        "# from io import open\n",
        "# import unicodedata\n",
        "import re\n",
        "import random\n",
        "import unicodedata\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiwtNgENbx2g"
      },
      "source": [
        "## Part 1: Seq2Seq Arithmetic model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1gWov3Gx67I"
      },
      "source": [
        "**Using RNN `seq2seq` model to \"learn\" simple arithmetics!**\n",
        "\n",
        "> Given the string \"54-7\", the model should return a prediction: \"47\".  \n",
        "> Given the string \"10+20\", the model should return a prediction: \"30\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxo92ZgTy6ED"
      },
      "source": [
        "- Watch Lukas Biewald's short [video](https://youtu.be/MqugtGD605k?si=rAH34ZTJyYDj-XJ1) explaining `seq2seq` models and his toy application (somewhat outdated).\n",
        "- You can find the code for his example [here](https://github.com/lukas/ml-class/blob/master/videos/seq2seq/train.py).    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEu_5YvqFPai"
      },
      "source": [
        "1.1) Using Lukas' code, implement a `seq2seq` network that can learn how to solve **addition AND substraction** of two numbers of maximum length of 4, using the following steps (similar to the example):      \n",
        "\n",
        "* Generate data; X: queries (two numbers), and Y: answers   \n",
        "* One-hot encode X and Y,\n",
        "* Build a `seq2seq` network (with LSTM, RepeatVector, and TimeDistributed layers)\n",
        "* Train the model.\n",
        "* While training, sample from the validation set at random so we can visualize the generated solutions against the true solutions.    \n",
        "\n",
        "Notes:  \n",
        "* The code in the example is quite old and based on Keras. You might have to adapt some of the code to overcome methods/code that is not supported anymore. Hint: for the evaluation part, review the type and format of the \"correct\" output - this will help you fix the unsupported \"model.predict_classes\".\n",
        "* Please use the parameters in the code cell below to train the model.     \n",
        "* Instead of using a `wandb.config` object, please use a simple dictionary instead.   \n",
        "* You don't need to run the model for more than 50 iterations (epochs) to get a gist of what is happening and what the algorithm is doing.\n",
        "* Extra credit if you can implement the network in PyTorch (this is not difficult).    \n",
        "* Extra credit if you are able to significantly improve the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U6p6_1VvBSa"
      },
      "source": [
        "ANSWER\n",
        "\n",
        "See implementation below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXJQqZbEbRup"
      },
      "source": [
        "1.2).\n",
        "\n",
        "a) Do you think this model performs well?  Why or why not?     \n",
        "b) What are its limitations?   \n",
        "c) What would you do to improve it?    \n",
        "d) Can you apply an attention mechanism to this model? Why or why not?   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lMpQC07vGG2"
      },
      "source": [
        "ANSWER\n",
        "\n",
        "a) It seems the model is performing well, given its accuracy and digit accuracy scores.\n",
        "\n",
        "b) The first limitation is that it's contrained to four digits. The 2nd limitation is that thwer's no error bound. Contrary to a human who might miscalculate but will return a number, the model might return \"--++4\".\n",
        "\n",
        "c) I thought to add a constraint to produce either a sequence of digits or a sequence starting with \"-\". Plus, I'd add that \"0\" can't be the first digit if the number has more than one digit.\n",
        "\n",
        "d) An Attention mechanism can be applied to the model. See implementation below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wvRhhOcgmrQ"
      },
      "source": [
        "1.3).  \n",
        "\n",
        "Add attention to the model. Evaluate the performance against the `seq2seq` you trained above. Which one is performing better?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtEJK5IZkk8j"
      },
      "source": [
        "1.4)\n",
        "\n",
        "Using any neural network architecture of your liking, build  a model with the aim to beat the best performing model in 1.1 or 1.3. Compare your results in a meaningful way, and add a short explanation to why you think/thought your suggested network is better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwZKyzoBKl4G"
      },
      "outputs": [],
      "source": [
        "config = {}\n",
        "config[\"training_size\"] = 40000\n",
        "config[\"digits\"] = 4\n",
        "config[\"hidden_size\"] = 128\n",
        "config[\"batch_size\"] = 128\n",
        "config[\"iterations\"] = 50\n",
        "chars = '0123456789-+ '"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6YxgNvo0W_o"
      },
      "source": [
        "SOLUTION:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GlF7abtLjz06",
        "outputId": "c3629136-c5cf-4805-b3ec-fa4dfe15294b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating data...\n",
            "Total addition questions: 40000\n",
            "Vectorization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m72,704\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m13\u001b[0m)               │           \u001b[38;5;34m1,677\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">72,704</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,677</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m205,965\u001b[0m (804.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,965</span> (804.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m205,965\u001b[0m (804.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,965</span> (804.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Iteration 1\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.2872 - loss: 2.1066 - val_accuracy: 0.4083 - val_loss: 1.6250\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
            "Q 40-875    T -835  ☒ -779 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 532-90    T 442   ☒ 233  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 221-26    T 195   ☒ 111  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 864-7646  T -6782 ☒ -6666\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 7670-34   T 7636  ☒ 6666 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 840-98    T 742   ☒ 18   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 4-754     T -750  ☒ -443 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 5119-5623 T -504  ☒ -313 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 65-2483   T -2418 ☒ -5333\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 5598-56   T 5542  ☒ 566  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 2\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4178 - loss: 1.5962 - val_accuracy: 0.4282 - val_loss: 1.5598\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 965-204   T 761   ☒ 555  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 859-75    T 784   ☒ 888  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 9057-9    T 9048  ☒ 898  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 5785-6    T 5779  ☒ 665  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 96-466    T -370  ☒ -55  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 73-92     T -19   ☒ -2   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 331-7     T 324   ☒ 220  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 15-603    T -588  ☒ -55  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 98-27     T 71    ☒ 18   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 781-9     T 772   ☒ 888  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 3\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4388 - loss: 1.5199 - val_accuracy: 0.4466 - val_loss: 1.4822\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 4-8516    T -8512 ☒ -8841\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 886-834   T 52    ☒ 833  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Q 4709-1598 T 3111  ☒ 4443 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Q 761-7917  T -7156 ☒ -7091\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "Q 3487-2017 T 1470  ☒ -422 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Q 11-42     T -31   ☒ -1   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Q 3564-305  T 3259  ☒ 3313 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Q 497-150   T 347   ☒ 443  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Q 1246-433  T 813   ☒ -13  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Q 456-105   T 351   ☒ 411  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 4\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4588 - loss: 1.4475 - val_accuracy: 0.4770 - val_loss: 1.3984\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 823-3     T 820   ☒ 800  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 6232-89   T 6143  ☒ 6268 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 39-6820   T -6781 ☒ -9888\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 1287-884  T 403   ☒ -22  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 14-8293   T -8279 ☒ -8888\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 3992-99   T 3893  ☒ 9994 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 6700-1    T 6699  ☒ 6660 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 9-6744    T -6735 ☒ -6644\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 17-979    T -962  ☒ -999 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 67-292    T -225  ☑ -225 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 5\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4860 - loss: 1.3725 - val_accuracy: 0.5035 - val_loss: 1.3124\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 23-3265   T -3242 ☒ -3288\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 95-212    T -117  ☒ -14  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 39-216    T -177  ☒ -18  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 883-399   T 484   ☒ 323  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 59-3300   T -3241 ☒ -3288\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 9772-2    T 9770  ☒ 9977 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 868-89    T 779   ☒ 858  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 8977-32   T 8945  ☒ 8837 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 9-2759    T -2750 ☒ -2295\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 4929-520  T 4409  ☒ 3956 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 6\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5166 - loss: 1.2920 - val_accuracy: 0.5331 - val_loss: 1.2507\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 7275-803  T 6472  ☒ 7092 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 2505-1    T 2504  ☒ 2055 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 3890-159  T 3731  ☒ 3922 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 4044-6804 T -2760 ☒ -4695\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 6389-92   T 6297  ☒ 6284 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 3-705     T -702  ☒ -705 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 7-554     T -547  ☒ -542 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 8-977     T -969  ☒ -972 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 9211-132  T 9079  ☒ 9022 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 5843-4255 T 1588  ☒ 4122 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 7\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5426 - loss: 1.2304 - val_accuracy: 0.5547 - val_loss: 1.2013\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Q 68-62     T 6     ☒ 1    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Q 6515-5    T 6510  ☒ 6511 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "Q 29-78     T -49   ☒ -54  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Q 3100-616  T 2484  ☒ 2433 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Q 20-184    T -164  ☒ -172 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Q 9445-4    T 9441  ☒ 9485 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "Q 99-72     T 27    ☒ 65   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Q 54-85     T -31   ☒ -34  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Q 9655-6    T 9649  ☒ 9546 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 2-5584    T -5582 ☑ -5582\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 8\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5654 - loss: 1.1745 - val_accuracy: 0.5701 - val_loss: 1.1554\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 7078-0    T 7078  ☒ 7098 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 3759-87   T 3672  ☒ 3747 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 0-1852    T -1852 ☒ -1880\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Q 28-554    T -526  ☒ -536 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 7078-0    T 7078  ☒ 7098 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 4-4365    T -4361 ☒ -4456\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 208-5     T 203   ☒ 295  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 89-394    T -305  ☒ -395 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 4551-9684 T -5133 ☒ -4022\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 3658-195  T 3463  ☒ 3687 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 9\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5825 - loss: 1.1303 - val_accuracy: 0.5724 - val_loss: 1.1524\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Q 6-472     T -466  ☒ -460 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 622-67    T 555   ☒ 599  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Q 880-5145  T -4265 ☒ -1466\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 71-1      T 70    ☑ 70   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 2004-436  T 1568  ☒ 1444 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 53-31     T 22    ☒ 18   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 413-40    T 373   ☒ 399  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 82-763    T -681  ☒ -699 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 6172-2163 T 4009  ☒ 5549 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 7-24      T -17   ☒ -20  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 10\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5930 - loss: 1.0949 - val_accuracy: 0.5867 - val_loss: 1.0929\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 4345-62   T 4283  ☒ 4419 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 13-318    T -305  ☒ -331 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 16-88     T -72   ☒ -79  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 52-103    T -51   ☒ -5   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Q 43-1881   T -1838 ☒ -1869\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Q 42-906    T -864  ☒ -866 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Q 95-7965   T -7870 ☒ -7699\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Q 593-7565  T -6972 ☒ -5099\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Q 1-4386    T -4385 ☒ -4381\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Q 1428-2635 T -1207 ☒ -11  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 11\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6076 - loss: 1.0564 - val_accuracy: 0.6069 - val_loss: 1.0497\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 256-6     T 250   ☒ 253  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 16-623    T -607  ☑ -607 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 5368-3    T 5365  ☒ 5331 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 7890-9    T 7881  ☒ 7798 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 256-6     T 250   ☒ 253  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 4-7543    T -7539 ☒ -7535\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 4292-185  T 4107  ☒ 3022 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 53-31     T 22    ☒ 18   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 43-2973   T -2930 ☒ -2855\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 3930-26   T 3904  ☒ 3917 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 12\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6178 - loss: 1.0297 - val_accuracy: 0.6109 - val_loss: 1.0361\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 447-612   T -165  ☒ -17  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 1-6271    T -6270 ☒ -6271\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 8-5119    T -5111 ☒ -5144\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 718-978   T -260  ☒ -221 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 747-1     T 746   ☒ 747  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 2-20      T -18   ☒ -10  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 14-4619   T -4605 ☒ -4616\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 31-96     T -65   ☒ -66  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 42-286    T -244  ☒ -243 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 378-38    T 340   ☒ 360  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 13\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6265 - loss: 1.0047 - val_accuracy: 0.6228 - val_loss: 1.0084\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 81-3330   T -3249 ☒ -3256\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 995-1     T 994   ☒ 984  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 1-6736    T -6735 ☒ -6736\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 23-168    T -145  ☒ -152 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 1-7559    T -7558 ☒ -7554\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 334-177   T 157   ☒ 274  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 945-1     T 944   ☑ 944  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 1286-9606 T -8320 ☒ -7862\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 2730-9584 T -6854 ☒ -6822\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 676-55    T 621   ☒ 628  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 14\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6378 - loss: 0.9746 - val_accuracy: 0.6276 - val_loss: 0.9872\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Q 83-77     T 6     ☒ 1    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "Q 3115-0    T 3115  ☒ 3109 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Q 70-722    T -652  ☒ -642 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Q 43-2973   T -2930 ☒ -2945\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Q 4551-9684 T -5133 ☒ -4222\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Q 1316-66   T 1250  ☒ 1239 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Q 149-233   T -84   ☒ -10  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Q 172-491   T -319  ☒ -347 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Q 8963-1844 T 7119  ☒ 8327 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Q 4195-51   T 4144  ☒ 4047 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 15\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6461 - loss: 0.9520 - val_accuracy: 0.6325 - val_loss: 0.9694\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 84-45     T 39    ☒ 31   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 823-732   T 91    ☒ 11   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 992-61    T 931   ☒ 911  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Q 98-8528   T -8430 ☒ -8444\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 716-5     T 711   ☒ 713  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 9281-863  T 8418  ☒ 8831 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 4503-9237 T -4734 ☒ -4111\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 4894-662  T 4232  ☒ 3121 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 1505-39   T 1466  ☒ 1473 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 929-5869  T -4940 ☒ -4991\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 16\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6535 - loss: 0.9330 - val_accuracy: 0.6380 - val_loss: 0.9553\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 566-8266  T -7700 ☒ -7677\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 4195-51   T 4144  ☒ 4157 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 9470-28   T 9442  ☒ 9495 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 27-2137   T -2110 ☒ -2206\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 422-7873  T -7451 ☒ -7346\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 697-4     T 693   ☒ 694  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 0-9293    T -9293 ☒ -9298\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 5306-3    T 5303  ☒ 5306 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 28-7      T 21    ☒ 13   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 84-2660   T -2576 ☒ -2596\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 17\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6611 - loss: 0.9116 - val_accuracy: 0.6448 - val_loss: 0.9373\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 31-637    T -606  ☒ -627 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 5423-3    T 5420  ☒ 5428 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 1-271     T -270  ☑ -270 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 8-2723    T -2715 ☒ -2716\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 1416-4    T 1412  ☒ 1444 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 56-4      T 52    ☒ 53   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Q 150-8947  T -8797 ☒ -8636\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Q 9-785     T -776  ☒ -779 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Q 91-319    T -228  ☒ -220 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Q 4485-1    T 4484  ☑ 4484 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 18\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6674 - loss: 0.8927 - val_accuracy: 0.6456 - val_loss: 0.9349\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "Q 46-1351   T -1305 ☒ -1308\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Q 853-6     T 847   ☒ 848  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 3-7313    T -7310 ☑ -7310\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 172-37    T 135   ☒ 120  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 312-397   T -85   ☒ -24  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 8-49      T -41   ☑ -41  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 2880-5    T 2875  ☒ 2874 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 926-307   T 619   ☒ 503  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 15-603    T -588  ☒ -597 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 7774-2    T 7772  ☒ 7793 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 19\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6714 - loss: 0.8808 - val_accuracy: 0.6542 - val_loss: 0.9056\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 34-384    T -350  ☒ -344 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 838-87    T 751   ☒ 777  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 904-52    T 852   ☒ 867  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 3-2090    T -2087 ☑ -2087\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 7325-73   T 7252  ☒ 7287 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 559-9     T 550   ☒ 548  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 48-22     T 26    ☒ 35   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 942-17    T 925   ☒ 817  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 113-156   T -43   ☑ -43  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 7369-5648 T 1721  ☒ 2894 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 20\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6826 - loss: 0.8549 - val_accuracy: 0.6621 - val_loss: 0.8878\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 341-222   T 119   ☒ 181  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 3341-3    T 3338  ☒ 3332 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 627-79    T 548   ☒ 575  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 2104-93   T 2011  ☒ 2922 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 2-324     T -322  ☑ -322 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 990-5     T 985   ☑ 985  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 453-4     T 449   ☒ 450  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 913-9100  T -8187 ☒ -8100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 95-3865   T -3770 ☒ -3774\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Q 11-171    T -160  ☒ -169 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 21\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6882 - loss: 0.8366 - val_accuracy: 0.6640 - val_loss: 0.8772\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Q 477-263   T 214   ☒ 102  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Q 136-5532  T -5396 ☒ -5380\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Q 96-466    T -370  ☑ -370 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Q 5-275     T -270  ☑ -270 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Q 75-872    T -797  ☒ -707 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 9592-246  T 9346  ☒ 9425 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "Q 6-2495    T -2489 ☒ -2390\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Q 28-5886   T -5858 ☒ -5842\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Q 11-2103   T -2092 ☒ -2099\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Q 5415-2    T 5413  ☒ 5421 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 22\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6929 - loss: 0.8224 - val_accuracy: 0.6654 - val_loss: 0.8751\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 2-4749    T -4747 ☒ -4777\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 22-1850   T -1828 ☒ -1867\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 6887-3    T 6884  ☒ 6885 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Q 531-161   T 370   ☒ 477  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 7819-2    T 7817  ☒ 7819 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 110-8     T 102   ☑ 102  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 7-5015    T -5008 ☒ -5096\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 5-2134    T -2129 ☒ -2229\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 244-0     T 244   ☑ 244  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 608-66    T 542   ☒ 555  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 23\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7011 - loss: 0.8052 - val_accuracy: 0.6737 - val_loss: 0.8535\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 9861-1473 T 8388  ☒ 9326 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 9274-62   T 9212  ☒ 9222 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 82-57     T 25    ☒ 27   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 9-477     T -468  ☑ -468 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 509-0     T 509   ☒ 508  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 6676-551  T 6125  ☒ 6101 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 8369-9    T 8360  ☒ 8361 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 25-58     T -33   ☒ -24  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 3-159     T -156  ☒ -155 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 18-893    T -875  ☒ -867 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 24\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7044 - loss: 0.7893 - val_accuracy: 0.6737 - val_loss: 0.8462\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 477-302   T 175   ☒ 255  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 595-81    T 514   ☒ 505  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 7-1289    T -1282 ☒ -1281\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 990-9     T 981   ☒ 989  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 189-2     T 187   ☑ 187  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 60-2885   T -2825 ☒ -2815\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 20-1270   T -1250 ☒ -1188\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 9-477     T -468  ☑ -468 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 75-8173   T -8098 ☒ -8015\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 563-752   T -189  ☒ -193 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 25\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7119 - loss: 0.7724 - val_accuracy: 0.6836 - val_loss: 0.8283\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Q 394-2098  T -1704 ☒ -2126\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Q 58-87     T -29   ☑ -29  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Q 136-152   T -16   ☒ -10  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Q 41-157    T -116  ☒ -112 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Q 35-76     T -41   ☒ -42  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Q 6237-639  T 5598  ☒ 5566 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Q 3778-265  T 3513  ☒ 3511 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Q 7700-530  T 7170  ☒ 7016 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Q 824-208   T 616   ☒ 621  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 718-182   T 536   ☒ 522  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 26\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7189 - loss: 0.7546 - val_accuracy: 0.6911 - val_loss: 0.8108\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 3145-663  T 2482  ☒ 2470 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 677-4214  T -3537 ☒ -3547\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 14-8293   T -8279 ☒ -8272\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 3977-5    T 3972  ☒ 3971 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 7710-9706 T -1996 ☒ -1207\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Q 9477-71   T 9406  ☒ 9475 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 352-547   T -195  ☒ -105 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Q 216-7     T 209   ☒ 217  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 7982-1    T 7981  ☒ 7989 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 8-9336    T -9328 ☒ -9322\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 27\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7220 - loss: 0.7428 - val_accuracy: 0.6811 - val_loss: 0.8319\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 595-81    T 514   ☒ 406  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 4-2197    T -2193 ☑ -2193\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "Q 35-76     T -41   ☒ -42  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 8-2284    T -2276 ☒ -2277\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Q 1846-988  T 858   ☒ 808  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 5247-8488 T -3241 ☒ -3464\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 65-861    T -796  ☒ -805 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Q 710-776   T -66   ☒ -64  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 8588-3271 T 5317  ☒ 5686 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 205-37    T 168   ☒ 166  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 28\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7237 - loss: 0.7358 - val_accuracy: 0.6973 - val_loss: 0.7857\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 516-7152  T -6636 ☒ -6660\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 1631-8352 T -6721 ☒ -6840\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Q 789-9062  T -8273 ☒ -8344\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 588-57    T 531   ☒ 532  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 2-721     T -719  ☒ -729 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 482-31    T 451   ☒ 452  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 35-448    T -413  ☒ -414 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Q 87-6110   T -6023 ☒ -6044\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Q 61-635    T -574  ☑ -574 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "Q 831-505   T 326   ☒ 330  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 29\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7346 - loss: 0.7093 - val_accuracy: 0.6964 - val_loss: 0.7795\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 27-24     T 3     ☒ -    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 46-1351   T -1305 ☒ -1296\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 1812-56   T 1756  ☑ 1756 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 5-9390    T -9385 ☒ -9399\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 38-63     T -25   ☒ -26  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 922-9     T 913   ☒ 912  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 395-616   T -221  ☒ -276 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 630-433   T 197   ☒ 128  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 8-21      T -13   ☑ -13  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 646-930   T -284  ☒ -231 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 30\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7413 - loss: 0.6951 - val_accuracy: 0.7033 - val_loss: 0.7632\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 3328-546  T 2782  ☒ 2762 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 8-9336    T -9328 ☒ -9329\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 696-921   T -225  ☒ -224 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 4195-51   T 4144  ☒ 4047 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 945-489   T 456   ☒ 455  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 343-334   T 9     ☒ 10   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 3768-6651 T -2883 ☒ -2933\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 50-414    T -364  ☒ -367 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 364-95    T 269   ☒ 277  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 585-70    T 515   ☑ 515  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 31\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7454 - loss: 0.6785 - val_accuracy: 0.7049 - val_loss: 0.7529\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 6788-9    T 6779  ☑ 6779 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 6-728     T -722  ☒ -724 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 3413-251  T 3162  ☒ 3999 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 8052-956  T 7096  ☒ 7239 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 62-8306   T -8244 ☒ -8285\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 5229-22   T 5207  ☒ 5219 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 347-970   T -623  ☒ -646 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 2-485     T -483  ☑ -483 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 91-36     T 55    ☑ 55   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 1091-7027 T -5936 ☒ -6192\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 32\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7513 - loss: 0.6651 - val_accuracy: 0.7115 - val_loss: 0.7435\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 1006-603  T 403   ☒ 110  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 7489-8    T 7481  ☒ 7480 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 97-5050   T -4953 ☒ -4903\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 8-3140    T -3132 ☒ -3103\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 5129-3    T 5126  ☒ 5129 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 208-34    T 174   ☒ 175  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 80-234    T -154  ☒ -155 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 4623-9853 T -5230 ☒ -5049\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 3-330     T -327  ☑ -327 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 2136-884  T 1252  ☒ 1342 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 33\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7565 - loss: 0.6497 - val_accuracy: 0.7163 - val_loss: 0.7319\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 863-2706  T -1843 ☒ -1847\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 56-4      T 52    ☒ 53   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 3830-6214 T -2384 ☒ -2500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 6191-5    T 6186  ☒ 6185 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 15-74     T -59   ☒ -69  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 7604-281  T 7323  ☒ 6418 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 918-4349  T -3431 ☒ -3455\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 2038-8    T 2030  ☒ 2092 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 2801-62   T 2739  ☒ 2738 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 8424-514  T 7910  ☒ 7890 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 34\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7629 - loss: 0.6302 - val_accuracy: 0.7256 - val_loss: 0.7111\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Q 4242-335  T 3907  ☒ 3989 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 481-6849  T -6368 ☒ -6308\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 6676-551  T 6125  ☒ 6155 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 238-43    T 195   ☑ 195  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 685-41    T 644   ☑ 644  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 104-527   T -423  ☒ -465 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 347-47    T 300   ☑ 300  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 6-9737    T -9731 ☒ -9729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Q 4-4263    T -4259 ☒ -4261\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 79-9046   T -8967 ☒ -8997\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 35\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7689 - loss: 0.6162 - val_accuracy: 0.7314 - val_loss: 0.6901\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Q 2843-3    T 2840  ☒ 2820 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Q 210-3     T 207   ☑ 207  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "Q 684-52    T 632   ☑ 632  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Q 1-146     T -145  ☑ -145 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Q 546-68    T 478   ☒ 488  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Q 9848-59   T 9789  ☒ 9898 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Q 3346-51   T 3295  ☒ 3394 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Q 1365-83   T 1282  ☒ 1362 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "Q 3553-229  T 3324  ☒ 3224 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "Q 5122-479  T 4643  ☒ 4646 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 36\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7781 - loss: 0.5927 - val_accuracy: 0.7296 - val_loss: 0.6973\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 11-6667   T -6656 ☒ -6666\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 2936-560  T 2376  ☒ 2355 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Q 75-42     T 33    ☑ 33   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 776-638   T 138   ☒ 133  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 954-418   T 536   ☒ 563  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 6887-3    T 6884  ☒ 6883 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 71-86     T -15   ☒ -54  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 60-46     T 14    ☒ 25   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 417-744   T -327  ☒ -303 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 462-4     T 458   ☑ 458  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 37\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7824 - loss: 0.5818 - val_accuracy: 0.7413 - val_loss: 0.6652\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 76-7396   T -7320 ☒ -7311\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 6676-551  T 6125  ☒ 6155 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 9239-2    T 9237  ☑ 9237 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 648-79    T 569   ☒ 579  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 174-870   T -696  ☒ -685 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 7778-627  T 7151  ☒ 7181 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 403-921   T -518  ☒ -581 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 75-407    T -332  ☒ -320 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 7-356     T -349  ☒ -348 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Q 8132-1959 T 6173  ☒ 6359 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 38\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7896 - loss: 0.5636 - val_accuracy: 0.7429 - val_loss: 0.6589\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 2-82      T -80   ☑ -80  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 7637-31   T 7606  ☒ 7605 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 9-2642    T -2633 ☒ -2634\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 886-678   T 208   ☒ 228  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 41-2705   T -2664 ☒ -2675\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 3417-33   T 3384  ☒ 3404 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 2-4430    T -4428 ☑ -4428\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 211-120   T 91    ☒ 190  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 3852-1528 T 2324  ☒ 3344 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 718-182   T 536   ☒ 534  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 39\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7954 - loss: 0.5495 - val_accuracy: 0.7547 - val_loss: 0.6281\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "Q 362-226   T 136   ☒ 135  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "Q 6947-6    T 6941  ☒ 6942 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Q 2-7546    T -7544 ☒ -7553\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Q 32-26     T 6     ☒ 4    \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "Q 5-275     T -270  ☒ -279 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Q 938-23    T 915   ☑ 915  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Q 22-691    T -669  ☒ -668 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Q 2337-979  T 1358  ☒ 2332 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Q 53-3      T 50    ☑ 50   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Q 2-8971    T -8969 ☒ -8979\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 40\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8041 - loss: 0.5285 - val_accuracy: 0.7574 - val_loss: 0.6208\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 9-4458    T -4449 ☒ -4450\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 709-156   T 553   ☒ 653  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 60-567    T -507  ☒ -508 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 781-9     T 772   ☒ 763  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 114-905   T -791  ☒ -792 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 984-88    T 896   ☒ 895  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 295-74    T 221   ☑ 221  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Q 2315-226  T 2089  ☒ 2992 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 935-1011  T -76   ☒ -14  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 3341-3    T 3338  ☒ 3348 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 41\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8124 - loss: 0.5093 - val_accuracy: 0.7652 - val_loss: 0.6063\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 8236-2    T 8234  ☑ 8234 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 4198-1    T 4197  ☑ 4197 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 3-6630    T -6627 ☒ -6628\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 6221-52   T 6169  ☒ 6190 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Q 14-340    T -326  ☑ -326 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 7280-18   T 7262  ☒ 7271 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Q 6184-0    T 6184  ☑ 6184 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "Q 7341-1893 T 5448  ☒ 5558 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Q 11-42     T -31   ☑ -31  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "Q 40-943    T -903  ☑ -903 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 42\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8166 - loss: 0.4992 - val_accuracy: 0.7661 - val_loss: 0.5996\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Q 608-66    T 542   ☒ 543  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 31-952    T -921  ☒ -929 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "Q 155-2441  T -2286 ☑ -2286\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Q 7-554     T -547  ☑ -547 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Q 728-61    T 667   ☑ 667  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Q 518-376   T 142   ☒ 13   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Q 8587-35   T 8552  ☒ 8553 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Q 390-678   T -288  ☑ -288 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Q 2-205     T -203  ☑ -203 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Q 69-36     T 33    ☑ 33   \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 43\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8193 - loss: 0.4899 - val_accuracy: 0.7755 - val_loss: 0.5834\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 5129-3    T 5126  ☒ 5124 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Q 2305-2810 T -505  ☒ -396 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Q 902-354   T 548   ☒ 558  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 6530-10   T 6520  ☒ 6510 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 546-68    T 478   ☑ 478  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 7963-84   T 7879  ☒ 7890 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 84-8008   T -7924 ☒ -7946\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 56-37     T 19    ☒ 18   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 5661-2856 T 2805  ☒ 1995 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 165-52    T 113   ☒ 123  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 44\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8275 - loss: 0.4692 - val_accuracy: 0.7779 - val_loss: 0.5733\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 1791-6019 T -4228 ☒ -4108\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 5038-0    T 5038  ☒ 5039 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 836-6467  T -5631 ☒ -5701\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 3-8437    T -8434 ☑ -8434\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 2690-4    T 2686  ☒ 2685 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 712-368   T 344   ☒ 354  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 40-5366   T -5326 ☒ -5335\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 91-319    T -228  ☒ -227 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 174-86    T 88    ☒ 97   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 803-4     T 799   ☒ 898  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 45\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8359 - loss: 0.4512 - val_accuracy: 0.7919 - val_loss: 0.5500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 606-979   T -373  ☒ -383 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 4309-26   T 4283  ☒ 4392 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 5730-4    T 5726  ☒ 5725 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 7-555     T -548  ☑ -548 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 280-4     T 276   ☑ 276  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 0-9776    T -9776 ☑ -9776\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 3-6630    T -6627 ☒ -6628\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 8-1396    T -1388 ☑ -1388\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 374-0     T 374   ☑ 374  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Q 9123-37   T 9086  ☒ 9076 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 46\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8429 - loss: 0.4337 - val_accuracy: 0.7916 - val_loss: 0.5411\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Q 941-392   T 549   ☒ 429  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "Q 1862-973  T 889   ☒ 897  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "Q 74-61     T 13    ☑ 13   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Q 8-831     T -823  ☑ -823 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Q 60-99     T -39   ☑ -39  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "Q 237-53    T 184   ☑ 184  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "Q 3-394     T -391  ☒ -392 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Q 9338-440  T 8898  ☒ 8993 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "Q 70-93     T -23   ☑ -23  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "Q 4807-1840 T 2967  ☒ 3234 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 47\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8470 - loss: 0.4211 - val_accuracy: 0.8024 - val_loss: 0.5225\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 7-1289    T -1282 ☑ -1282\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 1185-417  T 768   ☒ 70   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 82-624    T -542  ☒ -541 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 8-5436    T -5428 ☑ -5428\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Q 57-85     T -28   ☑ -28  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 621-243   T 378   ☒ 381  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 95-261    T -166  ☒ -176 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 5665-6637 T -972  ☒ -102 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 4189-3363 T 826   ☒ 174  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 920-608   T 312   ☒ 338  \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 48\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8545 - loss: 0.4055 - val_accuracy: 0.8009 - val_loss: 0.5247\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Q 345-2     T 343   ☑ 343  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "Q 2-2026    T -2024 ☒ -2004\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Q 36-2428   T -2392 ☒ -2303\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 8571-41   T 8530  ☒ 8539 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Q 2272-555  T 1717  ☒ 1667 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Q 3768-6651 T -2883 ☒ -2955\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Q 838-87    T 751   ☒ 752  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Q 663-3     T 660   ☒ 659  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Q 240-6     T 234   ☑ 234  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Q 54-209    T -155  ☑ -155 \n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration 49\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8552 - loss: 0.4009 - val_accuracy: 0.8047 - val_loss: 0.5174\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Q 31-4721   T -4690 ☒ -4680\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Q 843-91    T 752   ☑ 752  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Q 474-9     T 465   ☑ 465  \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Q 1333-5460 T -4127 ☒ -4103\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Q 6-4687    T -4681 ☒ -4680\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "Q 2038-8    T 2030  ☒ 2039 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "Q 73-13     T 60    ☑ 60   \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Q 4-9084    T -9080 ☒ -9099\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Q 167-3465  T -3298 ☒ -3388\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Q 596-6183  T -5587 ☒ -5697\n"
          ]
        }
      ],
      "source": [
        "# adapted from https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, TimeDistributed, RepeatVector, Dense\n",
        "\n",
        "\n",
        "class CharacterTable(object):\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one hot integer representation\n",
        "    + Decode the one hot integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One hot encode given string C.\n",
        "        # Arguments\n",
        "            num_rows: Number of rows in the returned one hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return ''.join(self.indices_char[x] for x in x)\n",
        "\n",
        "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
        "# int is DIGITS.\n",
        "maxlen = config[\"digits\"] + 1 + config[\"digits\"]\n",
        "\n",
        "# All the numbers, plus sign and space for padding.\n",
        "chars = '0123456789+- '\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print('Generating data...')\n",
        "while len(questions) < config[\"training_size\"]:\n",
        "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
        "                    for i in range(np.random.randint(1, config[\"digits\"] + 1))))\n",
        "    a, b = f(), f()\n",
        "    # Skip any addition questions we've already seen\n",
        "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # Pad the data with spaces such that it is always MAXLEN.\n",
        "    q = '{}-{}'.format(a, b)\n",
        "    query = q + ' ' * (maxlen - len(q))\n",
        "    ans = str(a - b)\n",
        "    # Answers can be of maximum size DIGITS + 1.\n",
        "    ans += ' ' * (config[\"digits\"] + 1 - len(ans))\n",
        "\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "\n",
        "print('Total addition questions:', len(questions))\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(questions), maxlen, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(questions), config[\"digits\"] + 1, len(chars)), dtype=bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, maxlen)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, config[\"digits\"] + 1)\n",
        "\n",
        "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
        "# digits.\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Explicitly set apart 10% for validation data that we never train over.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(config[\"hidden_size\"], input_shape=(maxlen, len(chars))))\n",
        "model.add(RepeatVector(config[\"digits\"] + 1))\n",
        "model.add(LSTM(config[\"hidden_size\"], return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(len(chars), activation='softmax')))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model each generation and show predictions against the validation\n",
        "# dataset.\n",
        "for iteration in range(1, config[\"iterations\"]):\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print('Iteration', iteration)\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=config[\"batch_size\"],\n",
        "              epochs=1,\n",
        "              validation_data=(x_val, y_val))\n",
        "#              validation_data=(x_val, y_val),callbacks=[WandbCallback()])\n",
        "    # Select 10 samples from the validation set at random so we can visualize\n",
        "    # errors.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        predict_x=model.predict(rowx)\n",
        "        preds=np.argmax(predict_x[0],axis=1)\n",
        "#        preds = model.predict_classes(rowx, verbose=0)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds, calc_argmax=False)\n",
        "        print('Q', q, end=' ')\n",
        "        print('T', correct, end=' ')\n",
        "        if correct == guess:\n",
        "            print('☑', end=' ')\n",
        "        else:\n",
        "            print('☒', end=' ')\n",
        "        print(guess)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed, Attention\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define parameters\n",
        "char_to_idx = {c: i for i, c in enumerate(chars)}\n",
        "idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
        "\n",
        "# Build Seq2Seq Model with Attention\n",
        "\n",
        "encoder_inputs = Input(shape=(maxlen, len(chars)))\n",
        "encoder_lstm = LSTM(config[\"hidden_size\"], return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "decoder_inputs = RepeatVector(config[\"digits\"] + 1)(state_h)\n",
        "decoder_lstm = LSTM(config[\"hidden_size\"], return_sequences=True)(decoder_inputs)\n",
        "\n",
        "attention = Attention()([decoder_lstm, encoder_outputs])\n",
        "decoder_combined = tf.keras.layers.Concatenate()([decoder_lstm, attention])\n",
        "\n",
        "decoder_dense = TimeDistributed(Dense(len(chars), activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_combined)\n",
        "\n",
        "model = Model(encoder_inputs, decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model using existing datasets\n",
        "model.fit(x_train, y_train, batch_size=config[\"batch_size\"],\\\n",
        "          epochs=config[\"iterations\"], validation_data=(x_val, y_val))\n",
        "\n",
        "# Function to decode predictions\n",
        "def decode_sequence(input_seq):\n",
        "    prediction = model.predict(input_seq)\n",
        "    pred_idx = np.argmax(prediction, axis=-1)\n",
        "    return ''.join(idx_to_char[idx] for idx in pred_idx[0]).strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv6frOMnb55w",
        "outputId": "c13a27b8-214b-4137-f98a-6ea41108d5e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.3039 - loss: 2.0875 - val_accuracy: 0.4221 - val_loss: 1.6410\n",
            "Epoch 2/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4341 - loss: 1.5959 - val_accuracy: 0.4414 - val_loss: 1.5521\n",
            "Epoch 3/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4484 - loss: 1.5315 - val_accuracy: 0.4462 - val_loss: 1.5015\n",
            "Epoch 4/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4566 - loss: 1.4864 - val_accuracy: 0.4572 - val_loss: 1.4842\n",
            "Epoch 5/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4706 - loss: 1.4317 - val_accuracy: 0.4770 - val_loss: 1.3949\n",
            "Epoch 6/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4872 - loss: 1.3802 - val_accuracy: 0.4959 - val_loss: 1.3578\n",
            "Epoch 7/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5112 - loss: 1.3147 - val_accuracy: 0.5248 - val_loss: 1.2762\n",
            "Epoch 8/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5351 - loss: 1.2544 - val_accuracy: 0.5306 - val_loss: 1.2853\n",
            "Epoch 9/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5516 - loss: 1.2082 - val_accuracy: 0.5574 - val_loss: 1.1833\n",
            "Epoch 10/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5689 - loss: 1.1618 - val_accuracy: 0.5647 - val_loss: 1.1644\n",
            "Epoch 11/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5783 - loss: 1.1322 - val_accuracy: 0.5765 - val_loss: 1.1265\n",
            "Epoch 12/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5920 - loss: 1.0962 - val_accuracy: 0.5911 - val_loss: 1.0967\n",
            "Epoch 13/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6021 - loss: 1.0702 - val_accuracy: 0.5987 - val_loss: 1.0706\n",
            "Epoch 14/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6103 - loss: 1.0523 - val_accuracy: 0.6095 - val_loss: 1.0463\n",
            "Epoch 15/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6217 - loss: 1.0185 - val_accuracy: 0.6130 - val_loss: 1.0245\n",
            "Epoch 16/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6303 - loss: 0.9948 - val_accuracy: 0.6175 - val_loss: 1.0159\n",
            "Epoch 17/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6375 - loss: 0.9761 - val_accuracy: 0.6225 - val_loss: 1.0032\n",
            "Epoch 18/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6445 - loss: 0.9561 - val_accuracy: 0.6350 - val_loss: 0.9718\n",
            "Epoch 19/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6527 - loss: 0.9370 - val_accuracy: 0.6353 - val_loss: 0.9652\n",
            "Epoch 20/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6594 - loss: 0.9165 - val_accuracy: 0.6364 - val_loss: 0.9602\n",
            "Epoch 21/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6663 - loss: 0.8970 - val_accuracy: 0.6487 - val_loss: 0.9277\n",
            "Epoch 22/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6733 - loss: 0.8799 - val_accuracy: 0.6563 - val_loss: 0.9126\n",
            "Epoch 23/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6796 - loss: 0.8640 - val_accuracy: 0.6566 - val_loss: 0.9025\n",
            "Epoch 24/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6840 - loss: 0.8496 - val_accuracy: 0.6603 - val_loss: 0.8921\n",
            "Epoch 25/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6900 - loss: 0.8330 - val_accuracy: 0.6639 - val_loss: 0.8868\n",
            "Epoch 26/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6944 - loss: 0.8169 - val_accuracy: 0.6729 - val_loss: 0.8574\n",
            "Epoch 27/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7014 - loss: 0.8007 - val_accuracy: 0.6743 - val_loss: 0.8556\n",
            "Epoch 28/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7057 - loss: 0.7871 - val_accuracy: 0.6820 - val_loss: 0.8296\n",
            "Epoch 29/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7119 - loss: 0.7704 - val_accuracy: 0.6831 - val_loss: 0.8302\n",
            "Epoch 30/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7167 - loss: 0.7565 - val_accuracy: 0.6903 - val_loss: 0.8090\n",
            "Epoch 31/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7231 - loss: 0.7410 - val_accuracy: 0.6895 - val_loss: 0.8110\n",
            "Epoch 32/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7290 - loss: 0.7236 - val_accuracy: 0.6927 - val_loss: 0.7968\n",
            "Epoch 33/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7305 - loss: 0.7190 - val_accuracy: 0.6962 - val_loss: 0.7868\n",
            "Epoch 34/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7392 - loss: 0.6985 - val_accuracy: 0.7007 - val_loss: 0.7693\n",
            "Epoch 35/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7445 - loss: 0.6827 - val_accuracy: 0.7104 - val_loss: 0.7540\n",
            "Epoch 36/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7482 - loss: 0.6702 - val_accuracy: 0.7133 - val_loss: 0.7414\n",
            "Epoch 37/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7540 - loss: 0.6570 - val_accuracy: 0.7120 - val_loss: 0.7513\n",
            "Epoch 38/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7564 - loss: 0.6480 - val_accuracy: 0.7140 - val_loss: 0.7366\n",
            "Epoch 39/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7604 - loss: 0.6364 - val_accuracy: 0.7189 - val_loss: 0.7275\n",
            "Epoch 40/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7678 - loss: 0.6191 - val_accuracy: 0.7249 - val_loss: 0.7078\n",
            "Epoch 41/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7729 - loss: 0.6063 - val_accuracy: 0.7269 - val_loss: 0.7037\n",
            "Epoch 42/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7727 - loss: 0.6016 - val_accuracy: 0.7316 - val_loss: 0.6901\n",
            "Epoch 43/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7835 - loss: 0.5792 - val_accuracy: 0.7302 - val_loss: 0.6850\n",
            "Epoch 44/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7883 - loss: 0.5637 - val_accuracy: 0.7275 - val_loss: 0.7004\n",
            "Epoch 45/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7923 - loss: 0.5570 - val_accuracy: 0.7385 - val_loss: 0.6786\n",
            "Epoch 46/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7972 - loss: 0.5461 - val_accuracy: 0.7469 - val_loss: 0.6449\n",
            "Epoch 47/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8035 - loss: 0.5256 - val_accuracy: 0.7484 - val_loss: 0.6408\n",
            "Epoch 48/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8070 - loss: 0.5171 - val_accuracy: 0.7437 - val_loss: 0.6472\n",
            "Epoch 49/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8105 - loss: 0.5091 - val_accuracy: 0.7562 - val_loss: 0.6225\n",
            "Epoch 50/50\n",
            "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8168 - loss: 0.4946 - val_accuracy: 0.7600 - val_loss: 0.6139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voVYROYNlO49"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-d0eIM6FeaM"
      },
      "source": [
        "## Part 2: A language translation model with attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80jhFbWPMW_a"
      },
      "source": [
        "In this part of the problem set we are going to implement a translation with a Sequence to Sequence Network and Attention model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgL38lJGTYaF"
      },
      "source": [
        "0) Please go over the NLP From Scratch: Translation with a Sequence to Sequence Network and Attention [tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html). This attention model is very similar to what was learned in class (Luong), but a bit different. What are the main differences between  Badahnau and Luong attention mechanisms?    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBX873GJlDl9"
      },
      "source": [
        "1.a) Using `!wget`, `!unzip` , download and extract the [hebrew-english](https://www.manythings.org/anki/) sentence pairs text file to the Colab `content/`  folder (or local folder if not using Colab).\n",
        "1.b) The `heb.txt` must be parsed and cleaned (see tutorial for requirements or change the code as you see fit).   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvIIlNvPlGWB"
      },
      "source": [
        "2.a) Use the tutorial example to build  and train a Hebrew to English translation model with attention (using the parameters in the code cell below). Apply the same `eng_prefixes` filter to limit the train/test data.   \n",
        "2.b) Evaluate your trained model randomly on 20 sentences.  \n",
        "2.c) Show the attention plot for 5 random sentences.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER\n",
        "\n",
        "See implementation below."
      ],
      "metadata": {
        "id": "37pMX1UDBVAf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcqtVxkclIWG"
      },
      "source": [
        "3) Do you think this model performs well? Why or why not? What are its limitations/disadvantages? What would you do to improve it?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER\n",
        "\n",
        "The model seems to perform well given its accuracy rates."
      ],
      "metadata": {
        "id": "lUWE5mAWDHuE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2VSrRNtlJub"
      },
      "source": [
        "4) Using any neural network architecture of your liking, build  a model with the aim to beat the model in 2.a. Compare your results in a meaningful way, and add a short explanation to why you think/thought your suggested network is better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-tVmomvXcKk"
      },
      "outputs": [],
      "source": [
        "# use the following parameters:\n",
        "MAX_LENGTH = 10\n",
        "hidden_size = 128\n",
        "epochs = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9-C4pLEXzCF"
      },
      "source": [
        "SOLUTION:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqWpQSoYiz4F",
        "outputId": "79456b31-17eb-4297-a4cd-3e039f9c58cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etXj6--FjPBW"
      },
      "outputs": [],
      "source": [
        "#!unzip \"/content/drive/MyDrive/Statistics Masters/Adv. computational learning and data analysis/Problem Set 3/heb-eng.zip\" -d \\\n",
        "#\"/content/drive/MyDrive/Statistics Masters/Adv. computational learning and data analysis/Problem Set 3/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WrHkLD6p813",
        "outputId": "446c9521-8673-46f8-d72e-e13d433212e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 128133 sentence pairs\n",
            "Trimmed to 9336 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "heb 6272\n",
            "eng 3109\n",
            "['אני צעיר', 'i m young']\n",
            "Reading lines...\n",
            "Read 128133 sentence pairs\n",
            "Trimmed to 9336 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "heb 6272\n",
            "eng 3109\n",
            "0m 40s (- 10m 5s) (5 6%) 1.7966\n",
            "1m 20s (- 9m 20s) (10 12%) 0.9527\n",
            "1m 59s (- 8m 39s) (15 18%) 0.5740\n",
            "2m 39s (- 7m 59s) (20 25%) 0.3442\n",
            "3m 19s (- 7m 19s) (25 31%) 0.2055\n",
            "3m 58s (- 6m 37s) (30 37%) 0.1257\n",
            "4m 37s (- 5m 56s) (35 43%) 0.0839\n",
            "5m 17s (- 5m 17s) (40 50%) 0.0620\n",
            "5m 57s (- 4m 37s) (45 56%) 0.0492\n",
            "6m 36s (- 3m 58s) (50 62%) 0.0410\n",
            "7m 16s (- 3m 18s) (55 68%) 0.0372\n",
            "7m 54s (- 2m 38s) (60 75%) 0.0338\n",
            "8m 33s (- 1m 58s) (65 81%) 0.0308\n",
            "9m 13s (- 1m 19s) (70 87%) 0.0292\n",
            "9m 52s (- 0m 39s) (75 93%) 0.0269\n",
            "10m 33s (- 0m 0s) (80 100%) 0.0267\n",
            "> אני מודע היטב לסכנות\n",
            "= i m well aware of the dangers\n",
            "< you re making me japanese <EOS>\n",
            "\n",
            "> אני שמחה שאתה פה\n",
            "= i m glad you re here\n",
            "< glad you re here <EOS>\n",
            "\n",
            "> אני נרגשת להיות כאן שוב\n",
            "= i m excited to be back here\n",
            "< i m excited to be back here <EOS>\n",
            "\n",
            "> אני עוד לא מוותרת\n",
            "= i m still not giving up\n",
            "< i m not giving up to say yet <EOS>\n",
            "\n",
            "> אנו מתביישים\n",
            "= we re ashamed\n",
            "< we re ashamed <EOS>\n",
            "\n",
            "> הוא לא מבחין בי\n",
            "= he s not paying any attention to me\n",
            "< he s not paying any attention me <EOS>\n",
            "\n",
            "> אני בעיצומו של המשחק עם החתול שלי\n",
            "= i m playing with my cat\n",
            "< i m playing with my cat <EOS>\n",
            "\n",
            "> אני גם מאד ישנוני היום\n",
            "= i m very sleepy today too\n",
            "< i m very sleepy today too <EOS>\n",
            "\n",
            "> מחר אני לוקחת לעצמי יום חופש\n",
            "= i am taking tomorrow off\n",
            "< i am taking tomorrow off tomorrow <EOS>\n",
            "\n",
            "> אנו במצב טוב\n",
            "= we re in good condition\n",
            "< we re in good condition <EOS>\n",
            "\n",
            "> את קנדית נכון?\n",
            "= you re canadian right?\n",
            "< you re canadian right? <EOS>\n",
            "\n",
            "> אתה שקרן טוב\n",
            "= you re a good liar\n",
            "< you re a good liar <EOS>\n",
            "\n",
            "> חוששני שלא נותר קפה\n",
            "= i m afraid there isn t any coffee left\n",
            "< i m afraid there isn t any coffee left <EOS>\n",
            "\n",
            "> הם חברים\n",
            "= they re friends\n",
            "< they re friends <EOS>\n",
            "\n",
            "> את נוקשת\n",
            "= you re strict\n",
            "< you re strict <EOS>\n",
            "\n",
            "> אני כותב טיוטא של הנאום\n",
            "= i am writing a draft of the speech\n",
            "< i am writing a draft of the speech <EOS>\n",
            "\n",
            "> הוא מעודכן\n",
            "= he is up to date\n",
            "< he is up to date <EOS>\n",
            "\n",
            "> אתה מעיד בשבועה\n",
            "= you are under oath\n",
            "< he s a world famous <EOS>\n",
            "\n",
            "> זאת רק בדיחה\n",
            "= i m just kidding\n",
            "< i m just kidding <EOS>\n",
            "\n",
            "> אני משוכנע שתום סיפר לך את זה\n",
            "= i m sure tom told you that\n",
            "< sure sure it to be doing that i trust <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "NLP From Scratch: Translation with a Sequence to Sequence Network and Attention\n",
        "*******************************************************************************\n",
        "**Author**: `Sean Robertson <https://github.com/spro>`_\n",
        "\n",
        "This tutorials is part of a three-part series:\n",
        "\n",
        "* `NLP From Scratch: Classifying Names with a Character-Level RNN <https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html>`__\n",
        "* `NLP From Scratch: Generating Names with a Character-Level RNN <https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html>`__\n",
        "* `NLP From Scratch: Translation with a Sequence to Sequence Network and Attention <https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html>`__\n",
        "\n",
        "This is the third and final tutorial on doing **NLP From Scratch**, where we\n",
        "write our own classes and functions to preprocess the data to do our NLP\n",
        "modeling tasks.\n",
        "\n",
        "In this project we will be teaching a neural network to translate from\n",
        "French to English.\n",
        "\n",
        ".. code-block:: sh\n",
        "\n",
        "    [KEY: > input, = target, < output]\n",
        "\n",
        "    > il est en train de peindre un tableau .\n",
        "    = he is painting a picture .\n",
        "    < he is painting a picture .\n",
        "\n",
        "    > pourquoi ne pas essayer ce vin delicieux ?\n",
        "    = why not try that delicious wine ?\n",
        "    < why not try that delicious wine ?\n",
        "\n",
        "    > elle n est pas poete mais romanciere .\n",
        "    = she is not a poet but a novelist .\n",
        "    < she not not a poet but a novelist .\n",
        "\n",
        "    > vous etes trop maigre .\n",
        "    = you re too skinny .\n",
        "    < you re all alone .\n",
        "\n",
        "... to varying degrees of success.\n",
        "\n",
        "This is made possible by the simple but powerful idea of the `sequence\n",
        "to sequence network <https://arxiv.org/abs/1409.3215>`__, in which two\n",
        "recurrent neural networks work together to transform one sequence to\n",
        "another. An encoder network condenses an input sequence into a vector,\n",
        "and a decoder network unfolds that vector into a new sequence.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/seq2seq.png\n",
        "   :alt:\n",
        "\n",
        "To improve upon this model we'll use an `attention\n",
        "mechanism <https://arxiv.org/abs/1409.0473>`__, which lets the decoder\n",
        "learn to focus over a specific range of the input sequence.\n",
        "\n",
        "**Recommended Reading:**\n",
        "\n",
        "I assume you have at least installed PyTorch, know Python, and\n",
        "understand Tensors:\n",
        "\n",
        "-  https://pytorch.org/ For installation instructions\n",
        "-  :doc:`/beginner/deep_learning_60min_blitz` to get started with PyTorch in general\n",
        "-  :doc:`/beginner/pytorch_with_examples` for a wide and deep overview\n",
        "-  :doc:`/beginner/former_torchies_tutorial` if you are former Lua Torch user\n",
        "\n",
        "\n",
        "It would also be useful to know about Sequence to Sequence networks and\n",
        "how they work:\n",
        "\n",
        "-  `Learning Phrase Representations using RNN Encoder-Decoder for\n",
        "   Statistical Machine Translation <https://arxiv.org/abs/1406.1078>`__\n",
        "-  `Sequence to Sequence Learning with Neural\n",
        "   Networks <https://arxiv.org/abs/1409.3215>`__\n",
        "-  `Neural Machine Translation by Jointly Learning to Align and\n",
        "   Translate <https://arxiv.org/abs/1409.0473>`__\n",
        "-  `A Neural Conversational Model <https://arxiv.org/abs/1506.05869>`__\n",
        "\n",
        "You will also find the previous tutorials on\n",
        ":doc:`/intermediate/char_rnn_classification_tutorial`\n",
        "and :doc:`/intermediate/char_rnn_generation_tutorial`\n",
        "helpful as those concepts are very similar to the Encoder and Decoder\n",
        "models, respectively.\n",
        "\n",
        "**Requirements**\n",
        "\"\"\"\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "######################################################################\n",
        "# Loading data files\n",
        "# ==================\n",
        "#\n",
        "# The data for this project is a set of many thousands of English to\n",
        "# French translation pairs.\n",
        "#\n",
        "# `This question on Open Data Stack\n",
        "# Exchange <https://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages>`__\n",
        "# pointed me to the open translation site https://tatoeba.org/ which has\n",
        "# downloads available at https://tatoeba.org/eng/downloads - and better\n",
        "# yet, someone did the extra work of splitting language pairs into\n",
        "# individual text files here: https://www.manythings.org/anki/\n",
        "#\n",
        "# The English to French pairs are too big to include in the repository, so\n",
        "# download to ``data/eng-fra.txt`` before continuing. The file is a tab\n",
        "# separated list of translation pairs:\n",
        "#\n",
        "# .. code-block:: sh\n",
        "#\n",
        "#     I am cold.    J'ai froid.\n",
        "#\n",
        "# .. note::\n",
        "#    Download the data from\n",
        "#    `here <https://download.pytorch.org/tutorial/data.zip>`_\n",
        "#    and extract it to the current directory.\n",
        "\n",
        "######################################################################\n",
        "# Similar to the character encoding used in the character-level RNN\n",
        "# tutorials, we will be representing each word in a language as a one-hot\n",
        "# vector, or giant vector of zeros except for a single one (at the index\n",
        "# of the word). Compared to the dozens of characters that might exist in a\n",
        "# language, there are many many more words, so the encoding vector is much\n",
        "# larger. We will however cheat a bit and trim the data to only use a few\n",
        "# thousand words per language.\n",
        "#\n",
        "# .. figure:: /_static/img/seq-seq-images/word-encoding.png\n",
        "#    :alt:\n",
        "#\n",
        "#\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# We'll need a unique index per word to use as the inputs and targets of\n",
        "# the networks later. To keep track of all this we will use a helper class\n",
        "# called ``Lang`` which has word → index (``word2index``) and index → word\n",
        "# (``index2word``) dictionaries, as well as a count of each word\n",
        "# ``word2count`` which will be used to replace rare words later.\n",
        "#\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"<unk>\"} # Add <unk> token\n",
        "        self.n_words = 3  # Count SOS, EOS, and <unk>\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    # Handle out-of-vocabulary words:\n",
        "    return [lang.word2index.get(word, lang.word2index['<unk>']) for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "# Initialize '<unk>' token in prepareData:\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs, True)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    # Adding <unk> token to word2index\n",
        "    input_lang.addWord('<unk>')\n",
        "    output_lang.addWord('<unk>')\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# The files are all in Unicode, to simplify we will turn Unicode\n",
        "# characters to ASCII, make everything lowercase, and trim most\n",
        "# punctuation.\n",
        "#\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    #s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    #s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
        "    s = re.sub(r\"[^a-zA-Z\\u0590-\\u05FF!?]+\", r\" \", s)  # Keep Hebrew characters\n",
        "    return s.strip()\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# To read the data file we will split the file into lines, and then split\n",
        "# lines into pairs. The files are all English → Other Language, so if we\n",
        "# want to translate from Other Language → English I added the ``reverse``\n",
        "# flag to reverse the pairs.\n",
        "#\n",
        "\n",
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open(\"/content/drive/MyDrive/Statistics Masters/Adv. computational learning and data analysis/Problem Set 3/heb.txt\", encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p[:-1])) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# Since there are a *lot* of example sentences and we want to train\n",
        "# something quickly, we'll trim the data set to only relatively short and\n",
        "# simple sentences. Here the maximum length is 10 words (that includes\n",
        "# ending punctuation) and we're filtering to sentences that translate to\n",
        "# the form \"I am\" or \"He is\" etc. (accounting for apostrophes replaced\n",
        "# earlier).\n",
        "#\n",
        "\n",
        "# MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(pair, reversed):\n",
        "    p = pair[::-1] if reversed else pair\n",
        "    t = len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[0].startswith(eng_prefixes)\n",
        "    return t\n",
        "    #return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "    #    len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "    #    p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs, reversed):\n",
        "    return [pair for pair in pairs if filterPair(pair, reversed = reversed)]\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# The full process for preparing the data is:\n",
        "#\n",
        "# -  Read text file and split into lines, split lines into pairs\n",
        "# -  Normalize text, filter by length and content\n",
        "# -  Make word lists from sentences in pairs\n",
        "#\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'heb', True)\n",
        "print(random.choice(pairs))\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# The Seq2Seq Model\n",
        "# =================\n",
        "#\n",
        "# A Recurrent Neural Network, or RNN, is a network that operates on a\n",
        "# sequence and uses its own output as input for subsequent steps.\n",
        "#\n",
        "# A `Sequence to Sequence network <https://arxiv.org/abs/1409.3215>`__, or\n",
        "# seq2seq network, or `Encoder Decoder\n",
        "# network <https://arxiv.org/pdf/1406.1078v3.pdf>`__, is a model\n",
        "# consisting of two RNNs called the encoder and decoder. The encoder reads\n",
        "# an input sequence and outputs a single vector, and the decoder reads\n",
        "# that vector to produce an output sequence.\n",
        "#\n",
        "# .. figure:: /_static/img/seq-seq-images/seq2seq.png\n",
        "#    :alt:\n",
        "#\n",
        "# Unlike sequence prediction with a single RNN, where every input\n",
        "# corresponds to an output, the seq2seq model frees us from sequence\n",
        "# length and order, which makes it ideal for translation between two\n",
        "# languages.\n",
        "#\n",
        "# Consider the sentence ``Je ne suis pas le chat noir`` → ``I am not the\n",
        "# black cat``. Most of the words in the input sentence have a direct\n",
        "# translation in the output sentence, but are in slightly different\n",
        "# orders, e.g. ``chat noir`` and ``black cat``. Because of the ``ne/pas``\n",
        "# construction there is also one more word in the input sentence. It would\n",
        "# be difficult to produce a correct translation directly from the sequence\n",
        "# of input words.\n",
        "#\n",
        "# With a seq2seq model the encoder creates a single vector which, in the\n",
        "# ideal case, encodes the \"meaning\" of the input sequence into a single\n",
        "# vector — a single point in some N dimensional space of sentences.\n",
        "#\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# The Encoder\n",
        "# -----------\n",
        "#\n",
        "# The encoder of a seq2seq network is a RNN that outputs some value for\n",
        "# every word from the input sentence. For every input word the encoder\n",
        "# outputs a vector and a hidden state, and uses the hidden state for the\n",
        "# next input word.\n",
        "#\n",
        "# .. figure:: /_static/img/seq-seq-images/encoder-network.png\n",
        "#    :alt:\n",
        "#\n",
        "#\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden\n",
        "\n",
        "######################################################################\n",
        "# The Decoder\n",
        "# -----------\n",
        "#\n",
        "# The decoder is another RNN that takes the encoder output vector(s) and\n",
        "# outputs a sequence of words to create the translation.\n",
        "#\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# Simple Decoder\n",
        "# ^^^^^^^^^^^^^^\n",
        "#\n",
        "# In the simplest seq2seq decoder we use only last output of the encoder.\n",
        "# This last output is sometimes called the *context vector* as it encodes\n",
        "# context from the entire sequence. This context vector is used as the\n",
        "# initial hidden state of the decoder.\n",
        "#\n",
        "# At every step of decoding, the decoder is given an input token and\n",
        "# hidden state. The initial input token is the start-of-string ``<SOS>``\n",
        "# token, and the first hidden state is the context vector (the encoder's\n",
        "# last hidden state).\n",
        "#\n",
        "# .. figure:: /_static/img/seq-seq-images/decoder-network.png\n",
        "#    :alt:\n",
        "#\n",
        "#\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden\n",
        "\n",
        "######################################################################\n",
        "# I encourage you to train and observe the results of this model, but to\n",
        "# save space we'll be going straight for the gold and introducing the\n",
        "# Attention Mechanism.\n",
        "#\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# Attention Decoder\n",
        "# ^^^^^^^^^^^^^^^^^\n",
        "#\n",
        "# If only the context vector is passed between the encoder and decoder,\n",
        "# that single vector carries the burden of encoding the entire sentence.\n",
        "#\n",
        "# Attention allows the decoder network to \"focus\" on a different part of\n",
        "# the encoder's outputs for every step of the decoder's own outputs. First\n",
        "# we calculate a set of *attention weights*. These will be multiplied by\n",
        "# the encoder output vectors to create a weighted combination. The result\n",
        "# (called ``attn_applied`` in the code) should contain information about\n",
        "# that specific part of the input sequence, and thus help the decoder\n",
        "# choose the right output words.\n",
        "#\n",
        "# .. figure:: https://i.imgur.com/1152PYf.png\n",
        "#    :alt:\n",
        "#\n",
        "# Calculating the attention weights is done with another feed-forward\n",
        "# layer ``attn``, using the decoder's input and hidden state as inputs.\n",
        "# Because there are sentences of all sizes in the training data, to\n",
        "# actually create and train this layer we have to choose a maximum\n",
        "# sentence length (input length, for encoder outputs) that it can apply\n",
        "# to. Sentences of the maximum length will use all the attention weights,\n",
        "# while shorter sentences will only use the first few.\n",
        "#\n",
        "# .. figure:: /_static/img/seq-seq-images/attention-decoder-network.png\n",
        "#    :alt:\n",
        "#\n",
        "#\n",
        "# Bahdanau attention, also known as additive attention, is a commonly used\n",
        "# attention mechanism in sequence-to-sequence models, particularly in neural\n",
        "# machine translation tasks. It was introduced by Bahdanau et al. in their\n",
        "# paper titled `Neural Machine Translation by Jointly Learning to Align and Translate <https://arxiv.org/pdf/1409.0473.pdf>`__.\n",
        "# This attention mechanism employs a learned alignment model to compute attention\n",
        "# scores between the encoder and decoder hidden states. It utilizes a feed-forward\n",
        "# neural network to calculate alignment scores.\n",
        "#\n",
        "# However, there are alternative attention mechanisms available, such as Luong attention,\n",
        "# which computes attention scores by taking the dot product between the decoder hidden\n",
        "# state and the encoder hidden states. It does not involve the non-linear transformation\n",
        "# used in Bahdanau attention.\n",
        "#\n",
        "# In this tutorial, we will be using Bahdanau attention. However, it would be a valuable\n",
        "# exercise to explore modifying the attention mechanism to use Luong attention.\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# .. note:: There are other forms of attention that work around the length\n",
        "#   limitation by using a relative position approach. Read about \"local\n",
        "#   attention\" in `Effective Approaches to Attention-based Neural Machine\n",
        "#   Translation <https://arxiv.org/abs/1508.04025>`__.\n",
        "#\n",
        "# Training\n",
        "# ========\n",
        "#\n",
        "# Preparing Training Data\n",
        "# -----------------------\n",
        "#\n",
        "# To train, for each pair we will need an input tensor (indexes of the\n",
        "# words in the input sentence) and target tensor (indexes of the words in\n",
        "# the target sentence). While creating these vectors we will append the\n",
        "# EOS token to both sequences.\n",
        "#\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "    input_lang, output_lang, pairs = prepareData('eng', 'heb', True)\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# Training the Model\n",
        "# ------------------\n",
        "#\n",
        "# To train we run the input sentence through the encoder, and keep track\n",
        "# of every output and the latest hidden state. Then the decoder is given\n",
        "# the ``<SOS>`` token as its first input, and the last hidden state of the\n",
        "# encoder as its first hidden state.\n",
        "#\n",
        "# \"Teacher forcing\" is the concept of using the real target outputs as\n",
        "# each next input, instead of using the decoder's guess as the next input.\n",
        "# Using teacher forcing causes it to converge faster but `when the trained\n",
        "# network is exploited, it may exhibit\n",
        "# instability <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf>`__.\n",
        "#\n",
        "# You can observe outputs of teacher-forced networks that read with\n",
        "# coherent grammar but wander far from the correct translation -\n",
        "# intuitively it has learned to represent the output grammar and can \"pick\n",
        "# up\" the meaning once the teacher tells it the first few words, but it\n",
        "# has not properly learned how to create the sentence from the translation\n",
        "# in the first place.\n",
        "#\n",
        "# Because of the freedom PyTorch's autograd gives us, we can randomly\n",
        "# choose to use teacher forcing or not with a simple if statement. Turn\n",
        "# ``teacher_forcing_ratio`` up to use more of it.\n",
        "#\n",
        "\n",
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# This is a helper function to print time elapsed and estimated time\n",
        "# remaining given the current time and progress %.\n",
        "#\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# The whole training process looks like this:\n",
        "#\n",
        "# -  Start a timer\n",
        "# -  Initialize optimizers and criterion\n",
        "# -  Create set of training pairs\n",
        "# -  Start empty losses array for plotting\n",
        "#\n",
        "# Then we call ``train`` many times and occasionally print the progress (%\n",
        "# of examples, time so far, estimated time) and average loss.\n",
        "#\n",
        "\n",
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "\n",
        "######################################################################\n",
        "# Plotting results\n",
        "# ----------------\n",
        "#\n",
        "# Plotting is done with matplotlib, using the array of loss values\n",
        "# ``plot_losses`` saved while training.\n",
        "#\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# Evaluation\n",
        "# ==========\n",
        "#\n",
        "# Evaluation is mostly the same as training, but there are no targets so\n",
        "# we simply feed the decoder's predictions back to itself for each step.\n",
        "# Every time it predicts a word we add it to the output string, and if it\n",
        "# predicts the EOS token we stop there. We also store the decoder's\n",
        "# attention outputs for display later.\n",
        "#\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "    return decoded_words, decoder_attn\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# We can evaluate random sentences from the training set and print out the\n",
        "# input, target, and output to make some subjective quality judgements:\n",
        "#\n",
        "\n",
        "def evaluateRandomly(encoder, decoder, n=20):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# Training and Evaluating\n",
        "# =======================\n",
        "#\n",
        "# With all these helper functions in place (it looks like extra work, but\n",
        "# it makes it easier to run multiple experiments) we can actually\n",
        "# initialize a network and start training.\n",
        "#\n",
        "# Remember that the input sentences were heavily filtered. For this small\n",
        "# dataset we can use relatively small networks of 256 hidden nodes and a\n",
        "# single GRU layer. After about 40 minutes on a MacBook CPU we'll get some\n",
        "# reasonable results.\n",
        "#\n",
        "# .. note::\n",
        "#    If you run this notebook you can train, interrupt the kernel,\n",
        "#    evaluate, and continue training later. Comment out the lines where the\n",
        "#    encoder and decoder are initialized and run ``trainIters`` again.\n",
        "#\n",
        "\n",
        "# hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)\n",
        "\n",
        "######################################################################\n",
        "#\n",
        "# Set dropout layers to ``eval`` mode\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# Visualizing Attention\n",
        "# ---------------------\n",
        "#\n",
        "# A useful property of the attention mechanism is its highly interpretable\n",
        "# outputs. Because it is used to weight specific encoder outputs of the\n",
        "# input sequence, we can imagine looking where the network is focused most\n",
        "# at each time step.\n",
        "#\n",
        "# You could simply run ``plt.matshow(attentions)`` to see attention output\n",
        "# displayed as a matrix. For a better viewing experience we will do the\n",
        "# extra work of adding axes and labels:\n",
        "#\n",
        "\n",
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    ax.tick_params(\"x\", labelrotation=45)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
        "\n",
        "evaluateAndShowAttention('את כל כך חמודה')\n",
        "\n",
        "evaluateAndShowAttention('אני לא מוכנה להכנע')\n",
        "\n",
        "evaluateAndShowAttention('אני רואה את הים')\n",
        "\n",
        "evaluateAndShowAttention('אני משוכנע שתום סיפר לך את זה')\n",
        "\n",
        "evaluateAndShowAttention('זאת רק בדיחה')"
      ],
      "metadata": {
        "id": "K5pTVkkxpat3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36699842-1932-454e-e426-5a17a4664939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = את כל כך חמודה\n",
            "output = you re so pretty dishonest <EOS>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-74bae3114fe3>:12: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
            "<ipython-input-62-74bae3114fe3>:14: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_yticklabels([''] + output_words)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAHCCAYAAACuSMMdAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPPdJREFUeJzt3X98j/X+x/HnZ7MfMluEzY+x8mMoP+dHjJNqUZ2zvk4pvw7DIUIRuknS4pRNkSWiFHL0Q+l3RMfYqeRUiNCOX5GFzfzaRtnY3t8/nH1qmdp8tutzffZ53Ltdt3J9rutzva81n+fn9b7e1/tyGGOMAACAZXzc3QAAALwN4QsAgMUIXwAALEb4AgBgMcIXAACLEb4AAFiM8AUAwGKELwAAFiN8AQCwGOELAIDFCF8AACxG+AIAYDHCFwAAixG+AABYjPAFgAqKJ8baF+ELABVMYeg6HA5J0vHjx7Vz506dPn3anc3CrxC+AFCBFBQUOEO3oKBA8+fPV1xcnFq0aKEPP/zQza1DoUrubgAAwHXGGDkcDvn4+OjMmTNKTEzUli1btGnTJvXs2VOhoaGqV6+eu5uJ/6HyBYAKwOFwaOPGjZo5c6aaN2+u9evXq0uXLtq3b5+MMYqMjFSXLl3c3Uz8D5UvAHi4c+fOKSUlRX//+98VFRWle++9V5MnT5YxRt9++602b96sBQsWyOFwqKCgQD4+1F3uRvgCgAc6evSo9u7dq86dO8vPz09XX3213nvvPV199dWqVq2apAvV8Mcff6yQkBDVrVtXkghemyB8AcDDfPfddxo6dKgiIyOVl5enbt26qVGjRhdtt3PnTiUmJmru3LmqU6eOG1qKS+ErEIAKraLd67p9+3Z17dpV7dq105gxY9StW7cirxcUFDjP+ZNPPtEtt9yi2NhYN7QUv4fKF0CFs2vXLmVkZCg0NFSNGzd23nrj6TIzMxUXF6ehQ4dqxowZRV4rvJZb2K2cn5+vZcuWqVu3bgoJCXFHc/E7qHwBVCgrVqxQTEyMJk+erKioKE2dOlWpqanublaZOHDggM6dO6chQ4Y4123atElJSUnq1q2b/u///k87d+6UJB05ckR9+vTRrFmzJFW8HgBPR/gCqDDeeust9evXT3PmzNFnn32m+fPn6+OPP9bcuXO1fft2dzfPZbm5ufrpp5+0b98+SdLChQv14IMPavny5apXr56OHDmi22+/XcePH1e9evU0atQoSb/cAwz7cBi+DgGoAJYuXapBgwbpo48+0u233+5c/+abb2rWrFlq27atRo0apeuuu86NrXTNkSNH1KtXL508eVIOh0P79+/XI488otjYWLVq1UoZGRmKjIxUYmKiRowY4e7m4ndwzRdAhZCWlqa33npLt99+u86dOyc/Pz9J0j333COHw6GkpCQlJibqkUceUfPmzd3c2pLJzc11VrsBAQGqXbu2Xn31Va1cuVKZmZnq1auXrr32WmdVm5WVpYiIiGJHPsNeCF8AHi05OVm1a9fW5MmTJUnZ2dlKSUlRhw4dFBYWJkm6++67lZubqyVLlqh69erubG6JpaamasqUKdqzZ4+OHDmiypUra8KECerTp4+zO/m3li1bJmOMx3y58GZ0OwPwWKtXr9btt9+uPXv2qGHDhpKkLVu2aOzYsbrjjjsUFxenmjVrOrfPyclR1apV3dXcEtu+fbv+9Kc/6e6771bnzp119uxZpaSk6M0331S/fv0uqt537NihRYsWadGiRUpJSVHr1q3d13iUCJUvAI+0YsUK9enTR35+fsrKynKub9u2rbp3767nnntOlSpVUt++fRUaGipJHhG8mZmZGjBggIYOHaqnn37auX7EiBGKjo7WmDFjVL16dT399NPy9/fXU089pfXr1ysrK0ufffaZWrRo4cbWo6QIXwAe580339SAAQO0YMECpaWlKTY2VgsWLHBOJvHoo48qMDBQU6ZMUaVKlTRy5EiPmVZx165dMsZo6NChkn55RKDD4dD999+v06dP69FHH9WAAQPUvn179e/fX82aNVP79u1Vu3ZtN7ceJUX4AvAoH3/8sfr06aNVq1bp1ltv1d69e3Xy5EmNGDFCDodDf/nLXyRJEyZMUKVKldSjRw+PCV7pQvgeOXJENWrUkCRn8EoXgrh///6aN2+eUlJS1K5dO9WrV49HBXogz/mNBABJ/v7+WrdunW699VZJUqNGjfTggw+qV69eGj58uFatWuXcduzYsWrcuLG7mlpiP/30kwoKCiRJdevW1bFjx7Rt27aLtvPx8VH9+vXl7++v48ePc++uByN8AXiElJQULV26VDfffLO6deum8+fPOwPr6quv1pgxY9S7d2/dddddWrNmjZtbW3JbtmxR7969dfDgQUlSs2bN1Lp1a02bNk27d++Ww+FQfn6+JOn8+fM6fvy46tevr3bt2rmz2XAR4QvA9vLy8rR27VqNHDlSr7zyiiSpUqVKRSq/a665RiNHjtTYsWN1zTXXuKuppbJt2zZ17txZkZGRioiIkCQ1aNBAffv21fbt2zV58mSlpqbK19dX0oVznjNnjg4cOKD27du7seVwFbcaeQGmlkNF8MMPP2jJkiV64YUX9OSTT2rw4MGSLv79Pn/+vCpVsv9wlm3btqlTp0568MEH9eSTT170+qOPPqqXX35ZkjRkyBD9/PPPOnXqlN577z2tXbtWbdu2tbrJKEP2/w3FZTl9+rQCAgLk5+cnh8NRoQO48Pujw+FwPtkFFUNOTo4CAwPl5+enBg0aaNCgQcrPz9cjjzwiSRo8ePBFv9+eELzbt2/XDTfccFHwxsfH6+TJk5ozZ46eeOIJtW3bVh9//LFWrFih6tWrKyoqShs2bFCzZs3c2HqUBSrfCuijjz7S7NmzVaVKFdWsWdP57bkiMsbIGCMfHx999tln+vnnn9W9e3dCuAJ4//339dRTTyk4OFi1a9fWokWLJEmHDh3SCy+8oIULFyoxMVFxcXFubmnpFBQUKDo6Wl9++aX27t3r7CKfMWOGEhMTtWzZMv35z38usk92draCg4M9pqpHCRhUKG+88YYJCAgwM2bMMLNmzTJNmzY1UVFR5ujRo+5uWpkrKChw/vfbb79tHA6HqV+/vsnLy3Njq6yVmZlpfvjhB3c3o8ytW7fO+Pv7m3nz5pnExETTqFEjExUVZTIyMowxxvz4448mPj7e+Pv7m2XLlrm5taWXnp5uGjRoYLp27WoyMzNNQkKCqV69ulmzZo1zm8Lf73Pnzl20Dp6P8K1AVq1aZfz8/Ir8BT5y5Ihp06aNadu2rcnMzHRj68rWnj17THJysjHGmDfffNP4+/ubqVOnmo4dO5rly5cbYyr+B9W0adNMdHS0ueqqq8wdd9xh1q1bZ/Lz893drDKRmJhoHnroIWOMMfn5+ebw4cMmKirKtGzZ0hw5csQYY8wPP/xgnnzySbNr1y53NrXUCv8fZWRkmNq1a5uaNWuaGjVqOP/e/vr/4YIFC8zrr7/ulnaifBG+FcRbb71lHA6HiYiIcK4rDJ/CAO7QoYOzcvB0w4YNM5UrVzYTJ040gYGBzg+u66+/3vTq1cvNrSt/Y8aMMfXr1zfvvvuuWblypenYsaO56aabzNKlS8358+fd3bzLtnLlSjNjxgxzzz33mNtuu61IL0ZGRoZp27atad26tTl06JAxxnjkuS5ZssTMmjXLGHPhnCIjI02TJk3Mnj17inxhnDJlinE4HCY1NdVdTUU5InwrgJ07d5qXX37ZLFmyxLRs2dJER0eb48ePF9kmPT3dREREmBtuuKHCVEe9e/c2DoejSKX/r3/9y4SGhhZZV9EsW7bMOByOIl+kTp48afr162duvPFGs3jxYo8MJWOMefLJJ029evVM06ZNTZMmTUx6eroxxpizZ886t/H19TV33nmnR57j4cOHTYsWLcz06dOd6zIyMkydOnVM165dzc6dO40xxsTHx5vKlSubTZs2uaupKGeEr4f78ccfja+vr5k4caIxxpgDBw6YRo0amS5duphTp04ZY36pDjIyMsz333/vtraWhd92JRd+ycjPzzf5+fnmxx9/NNHR0SY+Pt4Y45mV0R/59TmdP3/eWR2eOnXK9OvXz3Tr1s3jAvjYsWPm9OnTxhhjsrOzzSuvvGJCQ0Mv6sWYO3euqVKlivnmm2/c0MrLV/j/Yt26daZ9+/Zm48aNxphfruemp6ebOnXqmFtuucWMGDHCBAYGErwVHOHr4c6ePWuef/55ExISYubPn2+MMebgwYMmMjLS3Hjjjc7tPP36Z0FBgfMcPv/8czNz5kxz7733mpUrV170hSIpKclceeWV5scff3RHU8vNiy++aB566CHTvXt389prr5nvvvvO+Vrhh7gnBvC7775rbrjhBnPdddeZoUOHmnXr1hljLnRBR0REmJkzZxpjjPniiy9MvXr1zNdff+3O5rqkY8eO5m9/+1uxr2VkZJiQkBDjcDg87ssFSo/wrQB+/vlnk5CQYLp27ersity/f78JDw8306ZNc3PrykZh8L711lsmLCzM3H///eavf/2radiwoRkwYID57LPPnNtmZmaaZs2ameeee87jv3QUGj9+vGncuLF56qmnzL333muaN29u+vXrZz7//HPnNoVBWxjAMTExZsGCBbYO4MLR+a+++qqZP3+++dvf/mY6duxo3n//fWOMMQ899JC59dZbzaZNm8zPP/9s0tLS3Nzi0iv8HVy1apXp3Lmz2bFjh/O1U6dOmd27d5t//vOfxhhjTpw4Yfbt2+eWdsJahK8HWrNmjUlISDArVqwwmZmZ5uzZs+a///2vad++vfMamTHGxMXFmZEjR9r6w7c0CgeVrV692rnuww8/NLGxsWbQoEFFKt2xY8eavXv3uqOZZW7ChAmmSpUqRW4X++ijj8xf/vIXM2zYMHPs2DHn+sLr+adOnTKxsbEmNjbWefnBbj744APj4+Nj1q9f71y3detWM2LECNO2bVvzySefmGPHjpl69eqZ+++/330NLSNxcXGmZ8+ezssEycnJpmfPnqZp06bmhhtuMCdOnHBzC2ElwtfD5ObmmgceeMDUr1/ftGrVylStWtVERkaauLg4U6VKFZOSkmJOnTplNm3aZHr16mW+/fZbdze5TJw7d85Mnz7dGby/HgX74YcfmgYNGhT5EK8ozp49a2bPnu3s0fj1wKP33nvP1K5d22zZsqXIPoUBnJWV5RwVbDc5OTnmmmuuMT169DBnzpwp8tq2bdvM8OHDTYcOHcz69evNzp07PX7Eb0pKiqldu7bZtWuXWb58uRkyZIi54oorzJgxY5xVPrwLM1x5sMzMTEVHR+uOO+5Qenq6Nm7cqKpVq+q7777Tn//8Zz333HMV6jmfhbP7FM5eZX41pWD37t0VFRWlhIQEN7ey7BWeZ35+vnx9fYuc9/XXX6+hQ4c6H7xeyBNm+Nq8ebPGjBmjdu3a6b777lNkZKTzte3btysxMVE//vij1qxZo8DAQDe21HVTp07VnDlzdM011yg9PV2DBw9W9+7d1aVLF+c2pgJPAYuLMU+ZB/P395efn5969+6t9u3b69y5c0pPT9dXX32lNm3aVKjglX6Zs/fXoVIYMjVr1lSjRo3c1bRyVfiBXPhkm4KCAmcIBwUFqXbt2hftY/fglaSoqCjNmTNHw4cPl8Ph0MiRI53P3m3RooUmT56s6tWre3zwnj9/Xj/++KOaNWumLl266OGHH1ZISMhFc1ITvN6FyteD5efna9iwYXI4HBo/fryaN2/u7ia5xbx585SYmKj169dX2AAu9OsP64EDB2rPnj36/PPPncHsibZs2aLhw4erS5cuRQK4IsnKypIxxhm6ntAzgfJF+Hq41NRU5wfWxIkT1bBhQ3c3yVLz5s3T/fffr02bNnnVI9bi4uKUnJys/fv3y8/Pz9kl7am2bNmi0aNH67rrrqvwv8d0L0OS+Orl4Zo1a6annnpK+/btU1BQkLubY6lz587p9OnTXhe8P//8s66//npn8J4/f96jg1eS2rZtq6SkJK/4PSZ4IVH5Vhhnz571+Gtjl8Pbu+8q2iPmvPX3GN6H8AUAwGLeWzIAAOAmhC8AABYjfAEAsBjhCwCAxQhfAAAsRvhWQLm5uXr88ceVm5vr7qZYxhvPWfLO8/bGc5a897wrKm41qoCys7MVEhKirKwsBQcHu7s5lvDGc5a887y98Zwl7z3viorKFwAAixG+AABYrOLMS2czBQUFOnz4sKpWrWr5XK7Z2dlF/u0NvPGcJe88b288Z8m9522MUU5OjurUqVOu07mePXtWeXl5Lr+Pv7+/7acp5ZpvOfnxxx8VHh7u7mYAQJlJS0srt+eEnz17VldffbXS09Ndfq+wsDDt37/f1gFM5VtOqlat+qs/edtTTPg+h4orKyvL3U2wXHZ2tsLDw3/zuVa28vLylJ6eroMHD7o0oCw7O1v169dXXl4e4euNfulqdnjdI8ToTEFF5s0jja34LAuqWlVBLoR8gYd8/jDgCgAAi1H5AgBswxjjUu+Zp/S8Eb4AANsw//vHlf09Ad3OAABYjMoXAGAbBebC4sr+noDwBQDYhrdc86XbGQAAi1H5AgBso8AYl+7V9ZT7fAlfAIBt0O0MAADKBZUvAMA2vKXyJXwBALbBNV8AACzmLZUv13wBALAYlS8AwDa8ZW5nwhcAYBveMr0k3c4AAFiMyhcAYB8uDriShwy4InwBALbhLbca0e0MAIDFqHwBALbhLff5Er4AANvwlvCl2xkAAItR+QIAbMNbBlwRvgAA26Db2UMtXbpUV111lXJzc4us79mzpwYMGCBJmj9/vho2bCh/f39FRkbqn//8p3O7AwcOyOFwaOvWrc51p06dksPhUEpKihWnAABey5TBP56gwoXv3Xffrfz8fH3wwQfOdUePHtXKlSs1ZMgQvfvuuxozZozGjx+vHTt2aPjw4Ro8eLDWr1/v0nFzc3OVnZ1dZAEAoDgVLnwrV66sfv36afHixc51y5YtU/369dWtWzfNnDlTgwYN0siRI9WkSRONGzdOd955p2bOnOnScRMSEhQSEuJcwsPDXT0VAPA6hXM7u7J4ggoXvpI0bNgwffLJJzp06JAkacmSJRo0aJAcDodSU1MVHR1dZPvo6Gilpqa6dMxJkyYpKyvLuaSlpbn0fgDgjYx+ue57WYu7T6CEKuSAqzZt2qhVq1ZaunSpunfvrp07d2rlypUl2tfH58L3kV9ftD937twf7hcQEKCAgIDLazAAwKtUyMpXkoYOHaolS5Zo8eLFiomJcXYDN2vWTBs2bCiy7YYNG9S8eXNJUs2aNSVJR44ccb7+68FXAIDy41LV6+pDGSxUIStfSerXr58mTJighQsXaunSpc71Dz30kO655x61adNGMTEx+vDDD/XOO+9o7dq1ki5cM77++uuVmJioq6++WkePHtWjjz7qrtMAAK/iLff5VtjKNyQkRHfddZeCgoLUs2dP5/qePXvq2Wef1cyZM3XttdfqhRde0OLFi9WtWzfnNosWLdL58+cVFRWlsWPH6oknnrD+BAAAFVaFrXwl6dChQ+rfv/9F12Lvu+8+3XfffZfcr1mzZvriiy+KrPOUrgwA8GTeMslGhQzfkydPKiUlRSkpKXr++efd3RwAQAl5S7dzhQzfNm3a6OTJk5oxY4YiIyPd3RwAAIqokOF74MABdzcBAHA5XB2xTOULAEDpuDo/s6dMs0H4AgBsw9UpIpleEgAAFIvKFwBgG9xqBACAxbwlfOl2BgDAYlS+AADbYJINAAAsRrczAAAoF1S+AADb8JbKl/AFANiGt1zzpdsZAACLUfkCAGyDuZ0BALCYt8ztTPgCAGzDWwZccc0XAACLUfkCAGzDWypfwhcAYBvGxVuNPCV86XYGAMBiVL4AANug2xkAAIsZuRagnhG9hC/KgcPhfVczfH29869S1arV3d0Ey+1JT3d3Eyx3OifH3U2ocLzzEwMAYEveMrcz4QsAsA1vmV7S+/oHAQD4jXnz5ikiIkKBgYHq2LGjvvrqq9/dPikpSZGRkapcubLCw8P14IMP6uzZsyU+HuELALCNwrmdXVlKa/ny5Ro3bpzi4+O1ZcsWtWrVSj169NDRo0eL3f61117Tww8/rPj4eKWmpurll1/W8uXL9cgjj5T4mIQvAMA2Cm81cmUprWeeeUbDhg3T4MGD1bx5cy1YsEBXXHGFFi1aVOz2X3zxhaKjo9WvXz9FRESoe/fu6tu37x9Wy79G+AIAbKOswjc7O7vIkpubW+zx8vLytHnzZsXExDjX+fj4KCYmRhs3bix2n86dO2vz5s3OsP3++++1atUq3X777SU+T8IXAFDhhIeHKyQkxLkkJCQUu92xY8eUn5+v0NDQIutDQ0OVfonbyvr166dp06apS5cu8vPzU8OGDdWtW7dSdTsz2hkAYBtldatRWlqagoODnesDAgJcbluhlJQUTZ8+Xc8//7w6duyovXv3asyYMfrHP/6hKVOmlOg9CF8AgG2U1fSSwcHBRcL3UmrUqCFfX19lZGQUWZ+RkaGwsLBi95kyZYoGDBigoUOHSpJatGihM2fO6N5779XkyZPl4/PHncp0OwMAvJa/v7+ioqKUnJzsXFdQUKDk5GR16tSp2H1++umniwLW19dXUsmnxqTyBQDYhjserDBu3DjFxcWpXbt26tChg5KSknTmzBkNHjxYkjRw4EDVrVvXed04NjZWzzzzjNq0aePsdp4yZYpiY2OdIfxHCF8AgG24Y3rJ3r17KzMzU4899pjS09PVunVrrV692jkI6+DBg0Uq3UcffVQOh0OPPvqoDh06pJo1ayo2NlZPPvlkiY/pMJ7y/CUPk52drZCQEEkOORwOdzcH5YwHK3iPL7/7xt1NsNzpnBy1bdJEWVlZJbqOejkKPzPf+eILVQkKuuz3OXP6tO7s3Llc21oWvPMTAwBgS94ytzPhCwCwDWMuLK7s7wkY7QwAgMWofAEAtmFcHHDlKcOYCF8AgG2441YjdyB8AQC24Y5bjdyBa74AAFiMyhcAYBt0OwMAYDFvCV+6nQEAsBiVLwDANrxlwBXhCwCwDW+ZXpJuZwAALEblCwCwDW+Z25nw/Y28vDz5+/u7uxkA4JW85Zqv13c7d+vWTaNHj9bYsWNVo0YN9ejRQzt27NBtt92moKAghYaGasCAATp27Ji7mwoAFZ7RL7cbXdbi7hMoIa8PX0l65ZVX5O/vrw0bNigxMVE33XST2rRpo02bNmn16tXKyMjQPffc87vvkZubq+zs7CILAADFodtZUuPGjfXUU09Jkp544gm1adNG06dPd76+aNEihYeHa/fu3WrSpEmx75GQkKCpU6da0l4AqKjodvYiUVFRzv/etm2b1q9fr6CgIOfStGlTSdK+ffsu+R6TJk1SVlaWc0lLSyv3dgNAReNSl7OLs2NZicpXUpUqVZz/ffr0acXGxmrGjBkXbVe7du1LvkdAQIACAgLKpX0AgIqF8P2Ntm3b6u2331ZERIQqVeLHAwBWYm5nLzVq1CidOHFCffv21ddff619+/ZpzZo1Gjx4sPLz893dPACo2Apv9HVl8QCE72/UqVNHGzZsUH5+vrp3764WLVpo7NixuvLKK+Xjw48LAOA6r+9XTUlJuWhd48aN9c4771jfGADwcqbAyBS40O3swr5W8vrwBQDYiKs9x56RvXQ7AwBgNSpfAIBteMtoZ8IXAGAbhC8AABbzlvDlmi8AABaj8gUA2Aa3GgEAYDG6nQEAQLmg8gUA2Ia3VL6ELwDAPlx9OIKHhC/dzgAAWIzKFwBgG15S+BK+AAD7MMbFW408JH3pdgYAwGJUvgAA22C0MwAAFiN8AQCwmLeEL9d8AQCwGJUvAMA2vKXyJXwBAPZRIMmVJxMVlFlLyhXdzgAAWIzKFwBgG3Q7AygxXx9fdzfBLWrVqu/uJlhuT3q6u5tguZ9On7bsWN4yvSTdzgAAWIzKFwBgG3Q7AwBgMW8JX7qdAQCwGJUvAMA2TIGLjxR05R5hCxG+AAD7cLHb2VOGOxO+AADb4JovAAAoF1S+AADb8JbKl/AFANiHl0xxRbczAAAWo/IFANiGKbiwuLK/JyB8AQC2YeTiNV/R7QwAAIpB5QsAsA1GOwMAYDFvCV+6nQEAsBjhCwCwjcLK15XlcsybN08REREKDAxUx44d9dVXX/3u9qdOndKoUaNUu3ZtBQQEqEmTJlq1alWJj0e3MwDANtzxVKPly5dr3LhxWrBggTp27KikpCT16NFDu3btUq1atS7aPi8vT7fccotq1aqlFStWqG7duvrhhx905ZVXlviYhC8AwD7KaIar7OzsIqsDAgIUEBBQ7C7PPPOMhg0bpsGDB0uSFixYoJUrV2rRokV6+OGHL9p+0aJFOnHihL744gv5+flJkiIiIkrVTLqdAQAVTnh4uEJCQpxLQkJCsdvl5eVp8+bNiomJca7z8fFRTEyMNm7cWOw+H3zwgTp16qRRo0YpNDRU1113naZPn678/PwSt4/KFwBgG2U12jktLU3BwcHO9Zeqeo8dO6b8/HyFhoYWWR8aGqr//ve/xe7z/fffa926derfv79WrVqlvXv3auTIkTp37pzi4+NL1E7CFwBgG2X1XIXg4OAi4VuWCgoKVKtWLb344ovy9fVVVFSUDh06pKeffprwBQDgj9SoUUO+vr7KyMgosj4jI0NhYWHF7lO7dm35+fnJ19fXua5Zs2ZKT09XXl6e/P39//C4XPMFANiG1bca+fv7KyoqSsnJyc51BQUFSk5OVqdOnYrdJzo6Wnv37lVBwS9Pcdi9e7dq165douCVCF8AgI0U3mrkylJa48aN08KFC/XKK68oNTVV9913n86cOeMc/Txw4EBNmjTJuf19992nEydOaMyYMdq9e7dWrlyp6dOna9SoUSU+Jt3OAACv1rt3b2VmZuqxxx5Tenq6WrdurdWrVzsHYR08eFA+Pr/UquHh4VqzZo0efPBBtWzZUnXr1tWYMWM0ceLEEh+T8AUA2Ia75nYePXq0Ro8eXexrKSkpF63r1KmT/vOf/1zWsSTCFwBgIxdGO7sSvmXYmHLk1dd8V6xYoRYtWqhy5cq66qqrFBMTozNnzqigoEDTpk1TvXr1FBAQ4OyCAACgLHht5XvkyBH17dtXTz31lP76178qJydHn332mYwxevbZZzVr1iy98MILatOmjRYtWqQ77rhDO3fuVOPGjYt9v9zcXOXm5jr//NupzQAAf4xHClZwR44c0fnz53XnnXcqIiJCLVq00MiRIxUUFKSZM2dq4sSJ6tOnjyIjIzVjxgy1bt1aSUlJl3y/hISEIlOZhYeHW3cyAFBBuOupRlbz2vBt1aqVbr75ZrVo0UJ33323Fi5cqJMnTyo7O1uHDx9WdHR0ke2jo6OVmpp6yfebNGmSsrKynEtaWlp5nwIAVDwFxvXFA3ht+Pr6+upf//qXPv74YzVv3lzPPfecIiMjtX///st6v4CAAOd0ZuU5rRkAwPN5bfhKksPhUHR0tKZOnapvvvlG/v7+Sk5OVp06dbRhw4Yi227YsEHNmzd3U0sBwDsY/TK/82Ut7j6BEvLaAVdffvmlkpOT1b17d9WqVUtffvmlMjMz1axZMz300EOKj49Xw4YN1bp1ay1evFhbt27Vq6++6u5mA0DF5up1Ww+55uu14RscHKxPP/1USUlJys7OVoMGDTRr1izddttt6tGjh7KysjR+/HgdPXpUzZs31wcffHDJkc4AAJSG14Zvs2bNLnnvro+Pj+Lj40v8aCgAQNnwlluNvDZ8AQD2c7kPR/j1/p7AqwdcAQDgDlS+AADboNsZAACLeUv40u0MAIDFqHwBAPZROFuGK/t7AMIXAGAb3tLtTPgCAGzDFFxYXNnfE3DNFwAAi1H5AgBsg25nAAAs5i3hS7czAAAWo/IFANiGt1S+hC8AwDa8JXzpdgYAwGJUvgAA2/CWRwoSvgAA26DbGQAAlAsqXwCAjbj4YAV5RuVL+AIAbMNLHmpE+AIA7ONC+LpyzbcMG1OOuOYLAIDFqHwBALbBrUYoI8ZjukFw+XLzfnZ3E9xiz57N7m6C5W5p0cLdTbBcdna2ZcfiViMAAFAuqHwBALbhLZUv4QsAsA8Xw9dTrvPR7QwAgMWofAEA9uEls2wQvgAA2/CWW43odgYAwGJUvgAA2/CSXmfCFwBgH9xqBACAxbwlfLnmCwCAxah8AQC24S2VL+ELALANbjUCAADlgsoXAGAbdDsDAGA5F2/0lWeEL93OAABYjMoXAGAbdDsDAGAxb5lekm5nAAAsRuULALANb7nPl/AFANgG13wBALCYt4Qv13wBALAYlS8AwDa8pfIlfAEAtnHhViNXwrcMG1OOvKbbOSIiQklJSUXWLVmyRFdeeaVb2gMA8F4eX/nm5eXJ39/f3c0AAJQBb7nVyHaVb7du3TR69GiNHj1aISEhqlGjhqZMmeLshoiIiNA//vEPDRw4UMHBwbr33nslSZ9//rm6du2qypUrKzw8XA888IDOnDnjfM8ffvhBDz74oBwOhxwOh1JSUjR48GBlZWU51z3++OOaNm2arrvuuova1bp1a02ZMsW6HwQAeKPCKa5cWTyA7cJXkl555RVVqlRJX331lZ599lk988wzeumll5yvz5w5U61atdI333yjKVOmaN++fbr11lt111136dtvv9Xy5cv1+eefa/To0ZKkd955R/Xq1dO0adN05MgRHTlyRJ07d1ZSUpKCg4Od6yZMmKAhQ4YoNTVVX3/9tfN433zzjb799lsNHjz4km3Ozc1VdnZ2kQUAgOLYMnzDw8M1e/ZsRUZGqn///rr//vs1e/Zs5+s33XSTxo8fr4YNG6phw4ZKSEhQ//79NXbsWDVu3FidO3fWnDlztHTpUp09e1bVq1eXr6+vqlatqrCwMIWFhcnf318hISFyOBzOdUFBQapXr5569OihxYsXO4+3ePFi3XDDDbrmmmsu2eaEhASFhIQ4l/Dw8HL9GQFAReSuwnfevHmKiIhQYGCgOnbsqK+++qpE+73xxhtyOBzq2bNnqY5ny/C9/vrr5XA4nH/u1KmT9uzZo/z8fElSu3btimy/bds2LVmyREFBQc6lR48eKigo0P79+0t9/GHDhun111/X2bNnlZeXp9dee01Dhgz53X0mTZqkrKws55KWllbq4wKAtyu81ciVpbSWL1+ucePGKT4+Xlu2bFGrVq3Uo0cPHT169Hf3O3DggCZMmKCuXbuW+pgeOeCqSpUqRf58+vRpDR8+XA888MBF29avX7/U7x8bG6uAgAC9++678vf317lz59SrV6/f3ScgIEABAQGlPhYAwL2eeeYZDRs2zHlpccGCBVq5cqUWLVqkhx9+uNh98vPz1b9/f02dOlWfffaZTp06Vapj2jJ8v/zyyyJ//s9//qPGjRvL19e32O3btm2r7777To0aNbrke/r7+zsr599bJ0mVKlVSXFycFi9eLH9/f/Xp00eVK1e+jDMBAJSKi5NsFPY7/3bczaUKpLy8PG3evFmTJk1yrvPx8VFMTIw2btx4ycNMmzZNtWrV0t///nd99tlnpW6mLbudDx48qHHjxmnXrl16/fXX9dxzz2nMmDGX3H7ixIn64osvNHr0aG3dulV79uzR+++/7xxwJV0YJf3pp5/q0KFDOnbsmHPd6dOnlZycrGPHjumnn35ybj906FCtW7dOq1ev/sMuZwBA2Si81ciVRbowdujX43ASEhKKPd6xY8eUn5+v0NDQIutDQ0OVnp5e7D6ff/65Xn75ZS1cuPCyz9OWle/AgQP1888/q0OHDvL19dWYMWOctxQVp2XLlvr3v/+tyZMnq2vXrjLGqGHDhurdu7dzm2nTpmn48OFq2LChcnNzZYxR586dNWLECPXu3VvHjx9XfHy8Hn/8cUlyDtw6ceKEOnbsWN6nDABQ2U0vmZaWpuDgYOf6srosmJOTowEDBmjhwoWqUaPGZb+PLcPXz89PSUlJmj9//kWvHThwoNh92rdvr08++eSS73n99ddr27ZtF62fP39+sccxxujw4cMaOXJkyRsOALCF4ODgIuF7KTVq1JCvr68yMjKKrM/IyFBYWNhF2+/bt08HDhxQbGysc11BQYGkC5csd+3apYYNG/7hcW3Z7exumZmZmjt3rtLT03/33l4AQNkycnG0s0pXNfv7+ysqKkrJycnOdQUFBUpOTlanTp0u2r5p06bavn27tm7d6lzuuOMO3Xjjjdq6dWuJbzO1ZeXrbrVq1VKNGjX04osvqlq1au5uDgB4DXc81WjcuHGKi4tTu3bt1KFDByUlJenMmTPO4mvgwIGqW7euEhISFBgYeNEsiIXPCChudsRLsV34pqSkuLsJHvNIKgCA63r37q3MzEw99thjSk9PV+vWrbV69WrnIKyDBw/Kx6dsO4odhqQpF9nZ2QoJCfnfnxy/uy0qAu/8a+TjU/ztfxXZ2bxcdzfBctnZ2apRvbqysrJKdB31co8REhKiO3uNkZ/f5Q+OOncuV++seLZc21oWbFf5AgC8lym4sLiyvydgwBUAABaj8gUA2IY7Bly5A+ELALANbwlfup0BALAYlS8AwDa8pfIlfAEAtkH4AgBgsV8/mehy9/cEXPMFAMBiVL4AAPsw5sLiyv4egPAFANiGUemfTPTb/T0B3c4AAFiMyhcAYBuMdgYAwGIXwvfyn47gKeFLtzMAABaj8gUA2AbdzgAAWMxbwpduZwAALEblCwCwDW+pfAlfAIBtGFPg4mjny9/XSoRvOfP19ZPD4XB3MyzlKb/8cF1AwBXuboLlDp044e4mWC4nJ8e6g3nJ9JJc8wUAwGJUvgAA2/CWuZ0JXwCAjbg24EoeEr50OwMAYDEqXwCAbXCrEQAAFvOWW43odgYAwGJUvgAA26DbGQAAi3lL+NLtDACAxah8AQC24S2VL+ELALAPL5nbmfAFANjGhcklXbjViBmuAABAcah8AQC2wTVfAAAs5i3hS7czAAAWo/IFANiGt1S+hC8AwDZ4sAIAACgXVL4AANug2xkAAIt5S/jS7QwAgMWofAEA9sHczgAAWMv87x9X9vcEZdLt3K1bN40dO1aSFBERoaSkpBLtV5ptAQAVX+GtRq4snqDMK9+vv/5aVapUKeu3dZuUlBTdeOONOnnypK688kp3NwcAUAGUefjWrFmzrN8SAOAlGO18CWfOnNHAgQMVFBSk2rVra9asWUVe/3VXsjFGjz/+uOrXr6+AgADVqVNHDzzwQJHtf/rpJw0ZMkRVq1ZV/fr19eKLLxZ5ffv27brppptUuXJlXXXVVbr33nt1+vRp5+uDBg1Sz549NXPmTNWuXVtXXXWVRo0apXPnzjm3yc3N1YQJE1S3bl1VqVJFHTt2VEpKivP1H374QbGxsapWrZqqVKmia6+9VqtWrdKBAwd04403SpKqVasmh8OhQYMGlfZHBgAoocLwdWXxBKUO34ceekj//ve/9f777+uTTz5RSkqKtmzZUuy2b7/9tmbPnq0XXnhBe/bs0XvvvacWLVoU2WbWrFlq166dvvnmG40cOVL33Xefdu3aJelC0Pfo0UPVqlXT119/rbfeektr167V6NGji7zH+vXrtW/fPq1fv16vvPKKlixZoiVLljhfHz16tDZu3Kg33nhD3377re6++27deuut2rNnjyRp1KhRys3N1aeffqrt27drxowZCgoKUnh4uN5++21J0q5du3TkyBE9++yzxZ5rbm6usrOziywAABSnVN3Op0+f1ssvv6xly5bp5ptvliS98sorqlevXrHbHzx4UGFhYYqJiZGfn5/q16+vDh06FNnm9ttv18iRIyVJEydO1OzZs7V+/XpFRkbqtdde09mzZ7V06VLndeS5c+cqNjZWM2bMUGhoqKQLVencuXPl6+urpk2b6s9//rOSk5M1bNgwHTx4UIsXL9bBgwdVp04dSdKECRO0evVqLV68WNOnT9fBgwd11113Ob8YXHPNNc72Va9eXZJUq1at373mm5CQoKlTp5bmxwkA+A26nYuxb98+5eXlqWPHjs511atXV2RkZLHb33333fr55591zTXXaNiwYXr33Xd1/vz5Itu0bNnS+d8Oh0NhYWE6evSoJCk1NVWtWrUqMoArOjpaBQUFzupYkq699lr5+vo6/1y7dm3ne2zfvl35+flq0qSJgoKCnMu///1v7du3T5L0wAMP6IknnlB0dLTi4+P17bfflubHIkmaNGmSsrKynEtaWlqp3wMA4OpIZ88Y7VyuM1yFh4dr165dev7551W5cmWNHDlSf/rTn4pcj/Xz8yuyj8PhUEFB6X54v/cep0+flq+vrzZv3qytW7c6l9TUVGcX8tChQ/X9999rwIAB2r59u9q1a6fnnnuuVG0ICAhQcHBwkQUAgOKUKnwbNmwoPz8/ffnll851J0+e1O7duy+5T+XKlRUbG6s5c+YoJSVFGzdu1Pbt20t0vGbNmmnbtm06c+aMc92GDRvk4+NzyWr7t9q0aaP8/HwdPXpUjRo1KrKEhYU5twsPD9eIESP0zjvvaPz48Vq4cKEkyd/fX5KUn59fouMBAC4fA66KERQUpL///e966KGHtG7dOu3YsUODBg2Sj0/xb7NkyRK9/PLL2rFjh77//nstW7ZMlStXVoMGDUp0vP79+yswMFBxcXHasWOH1q9fr/vvv18DBgxwXu/9I02aNFH//v01cOBAvfPOO9q/f7+++uorJSQkaOXKlZKksWPHas2aNdq/f7+2bNmi9evXq1mzZpKkBg0ayOFw6KOPPlJmZmaRkdYAgDJWOL2kK4sHKHW389NPP62uXbsqNjZWMTEx6tKli6Kioord9sorr9TChQsVHR2tli1bau3atfrwww911VVXlehYV1xxhdasWaMTJ06offv26tWrl26++WbNnTu3VG1evHixBg4cqPHjxysyMlI9e/bU119/rfr160u6UNWOGjVKzZo106233qomTZro+eeflyTVrVtXU6dO1cMPP6zQ0NCLRloDAFBaDuMpNbqHyc7OVkhIiHx9/eRwONzdHEt5yvRucF1AwBXuboLldh7Y6+4mWC4nJ0ctGzZUVlZWuY1nKfzMbNMmRr6+lz//U37+eX3zzdpybWtZ4MEKAADb8JZbjQhfAIBtuPpwBE/peSvXW40AAMDFqHwBALZBtzMAABbzlvCl2xkAAIsRvgAA23DXDFfz5s1TRESEAgMD1bFjR3311VeX3HbhwoXq2rWrqlWrpmrVqikmJuZ3ty8O4QsAsA13hO/y5cs1btw4xcfHa8uWLWrVqpV69OjhfEDPb6WkpKhv375av369Nm7cqPDwcHXv3l2HDh0q8TEJXwCAV3vmmWc0bNgwDR48WM2bN9eCBQt0xRVXaNGiRcVu/+qrr2rkyJFq3bq1mjZtqpdeekkFBQVKTk4u8TEJXwCAfZgC1xddmDHr10tubm6xh8vLy9PmzZsVExPjXOfj46OYmBht3LixRE3+6aefdO7cOefz30uC8AUA2IYpg3+kC0+qCwkJcS4JCQnFHu/YsWPKz8+/6GE9oaGhSk9PL1GbJ06cqDp16hQJ8D/CrUYAgAonLS2tyNzOAQEB5XKcxMREvfHGG0pJSVFgYGCJ9yN8AQC2UVb3+QYHB5fowQo1atSQr6+vMjIyiqzPyMgo8sz34sycOVOJiYlau3atWrZsWap20u0MALANq0c7+/v7KyoqqshgqcLBU506dbrkfk899ZT+8Y9/aPXq1WrXrl2pz5PKFwBgG+54sMK4ceMUFxendu3aqUOHDkpKStKZM2c0ePBgSdLAgQNVt25d53XjGTNm6LHHHtNrr72miIgI57XhoKAgBQUFleiYhC8AwKv17t1bmZmZeuyxx5Senq7WrVtr9erVzkFYBw8elI/PLx3F8+fPV15ennr16lXkfeLj4/X444+X6JgO4ykTYXqYwgdD+/r6yeFwuLs5lvKUR3rBdQEBV7i7CZbbeWCvu5tguZycHLVs2LBcH1Bf+JnZpEl7+fpefl2Yn39eu3d/Xa5tLQtUvgAA2+DBCgAAoFxQ+QIAbMNbKl/CFwBgH0aSKwHqGdlLtzMAAFaj8gUA2IZRgYwu/w4RI8+424LwLWeVKvl73a1Gubk/ubsJlqtUyc/dTXCL/PPn3N0Ey+V7yDXFsmTlOXvLNV+6nQEAsBiVLwDARlyrfD1lxBXhCwCwDW/pdiZ8AQC2ceHBCi4MuPKQ6W255gsAgMWofAEAtkG3MwAAFvOW8KXbGQAAi1H5AgDswxgX53b2jMqX8AUA2Ib53z+u7O8J6HYGAMBiVL4AANvwlvt8CV8AgG14y2hnwhcAYBveEr5c8wUAwGJUvgAA2/CWypfwBQDYhreEL93OAABYjMoXAGAbFyrfy79dyFMqX8IXAGAfXjK9JN3OAABYjMoXAGAb3jK3M+ELALANRjsDAIByQeULALCNCw9WcG1/T0D4AgBsg25nN3M4HMUub7zxhnOb/Px8zZ49Wy1atFBgYKCqVaum2267TRs2bCjyXvn5+UpMTFTTpk1VuXJlVa9eXR07dtRLL71k9WkBAH5HYfi6sngCW1W+J0+elJ+fn4KCgiRJixcv1q233lpkmyuvvFLShf9Bffr00dq1a/X000/r5ptvVnZ2tubNm6du3brprbfeUs+ePSVJU6dO1QsvvKC5c+eqXbt2ys7O1qZNm3Ty5Enn+x4+fFi1atVSpUq2+pEAACogtyfN+fPntWbNGi1ZskQffvihvvzyS7Vq1UrShaANCwsrdr8333xTK1as0AcffKDY2Fjn+hdffFHHjx/X0KFDdcstt6hKlSr64IMPNHLkSN19993O7QqPUWjhwoWaP3++/va3vykuLk4tWrQoh7MFAPweup3L2fbt2zV+/HjVq1dPAwcOVM2aNbV+/fqLQvFSXnvtNTVp0qRI8BYaP368jh8/rn/961+SpLCwMK1bt06ZmZmXfL+JEyfq2WefVWpqqtq2bau2bdtqzpw5v7vPr+Xm5io7O7vIAgAoLVe7nAnfixw/flzPPvus2rZtq3bt2un777/X888/ryNHjuj5559Xp06dimzft29fBQUFFVkOHjwoSdq9e7eaNWtW7HEK1+/evVuS9MwzzygzM1NhYWFq2bKlRowYoY8//rjIPoGBgerdu7dWrlypQ4cOaeDAgVqyZInq1q2rnj176t1339X58+cveW4JCQkKCQlxLuHh4Zf9cwIAVGyWhu9zzz2nsWPHKigoSHv37tW7776rO++8U/7+/sVuP3v2bG3durXIUqdOHefrJe1eaN68uXbs2KH//Oc/GjJkiI4eParY2FgNHTq02O1r1aqlsWPHasuWLXr//fe1ceNG3XnnndqxY8cljzFp0iRlZWU5l7S0tBK1DQDwK6bA9cUDWHrN995771WlSpW0dOlSXXvttbrrrrs0YMAAdevWTT4+F38PCAsLU6NGjYp9ryZNmig1NbXY1wrXN2nSxLnOx8dH7du3V/v27TV27FgtW7ZMAwYM0OTJk3X11VcX2T8nJ0crVqzQP//5T3366ae64YYbFBcXp+bNm1/y3AICAhQQEPCHPwMAwKVdmB6y4k8vaWnlW6dOHT366KPavXu3Vq9eLX9/f915551q0KCBHn74Ye3cubPE79WnTx/t2bNHH3744UWvzZo1S1dddZVuueWWS+5fGKRnzpyRdOF2pI8//lj9+vVTaGioEhMTdfPNN+v7779XcnKyBg4ceMkKHQCA0nDbgKvOnTvrhRdeUHp6up5++mlt3bpVrVq10vbt253bnDp1Sunp6UWWwrDs06eP/vrXvyouLk4vv/yyDhw4oG+//VbDhw/XBx98oJdeeklVqlSRJPXq1UuzZ8/Wl19+qR9++EEpKSkaNWqUmjRpoqZNm0qSpk+frr59+6pq1apau3atdu3apcmTJ6t+/frW/3AAwEt5y32+DmOjlh4+fFhBQUEKDg6Ww+EodpuEhAQ9/PDDki7cppSUlKQlS5Zoz549CgwMVKdOnTRlyhRFR0c791m4cKFef/117dixQ1lZWQoLC9NNN92kxx9/XA0aNJAkHThwQGFhYQoMDCyTc8nOzlZISIgCAqpc8lwqqtzcn9zdBMtVquTn7ia4hY/DtvP0lJudaQfc3QTL5eTkqE2jRsrKylJwcHC5HKPwMzM4+Co5XPi9MqZA2dnHy7WtZcFW4VuREL7ehfD1HoQv4VsW3D7JBgAAhVx9MAIPVgAAoJQu9MW6MsNVmTWlXBG+AADbcPVKqKdcSfW+CzYAALgZlS8AwDa8pfIlfAEA9uFqeHpI+NLtDACAxah8AQC2YVQg6fLnRvCUuZ0JXwCAbXjLNV+6nQEAsBiVLwDANryl8iV8AQC24S3hS7czAAAWo/IFANiGt1S+hC8AwDYuPJXIhVuNCF8AAErHWypfrvkCAGAxKl8AgH14ydzOhC8AwDZcnR7SU6aXpNsZAACLUfkCAGyD0c4AAFiM0c4AAKBcUPmWk8JvX57yLawscc7ew1MGt5SlnJwcdzfBcqf/d85W/Z57w98nwrecFP4Fzcv7yc0tgRXOn89zdxNgkTaNGrm7CW6Tk5OjkJCQcnlvf39/hYWFKT093eX3CgsLk7+/fxm0qvw4jDd8xXCDgoICHT58WFWrVpXDcfmDBy5Hdna2wsPDlZaWpuDgYEuP7S7eeM6Sd563N56z5N7zNsYoJydHderUkY9P+V2tPHv2rPLyXP8i6+/vr8DAwDJoUfmh8i0nPj4+qlevnlvbEBwc7FUfTpJ3nrPkneftjecsue+8y6vi/bXAwEDbh2ZZYcAVAAAWI3wBALAY4VsBBQQEKD4+XgEBAe5uimW88Zwl7zxvbzxnyXvPu6JiwBUAABaj8gUAwGKELwAAFiN8AQCwGOELAIDFCF8AACxG+AIAYDHCFwAAixG+AABY7P8BGOoXPttp3iYAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = אני לא מוכנה להכנע\n",
            "output = i m not ready to give up without you <EOS>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-74bae3114fe3>:12: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
            "<ipython-input-62-74bae3114fe3>:14: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_yticklabels([''] + output_words)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-74bae3114fe3>:12: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "אני רואה את הים\n",
            "output = i m watching my job <EOS>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-74bae3114fe3>:14: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_yticklabels([''] + output_words)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = אני משוכנע שתום סיפר לך את זה\n",
            "output = sure sure it to be doing that i trust <EOS>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-74bae3114fe3>:12: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
            "<ipython-input-62-74bae3114fe3>:14: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_yticklabels([''] + output_words)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = זאת רק בדיחה\n",
            "output = i m just kidding <EOS>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-74bae3114fe3>:12: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
            "<ipython-input-62-74bae3114fe3>:14: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_yticklabels([''] + output_words)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYqwDHVfGkkI",
        "outputId": "74b1bda2-e95d-4663-93d0-b75c6535f0c4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/PS3_Attention_Please_2024_ID_310320650.ipynb  # Add --execute to pre-run the notebook and resolve dependencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ_0gdAEFmY-",
        "outputId": "743aff9a-bfe4-45cc-f3e3-a1baccc4fc5c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/PS3_Attention_Please_2024_ID_310320650.ipynb to html\n",
            "[NbConvertApp] WARNING | Alternative text is missing on 5 image(s).\n",
            "[NbConvertApp] Writing 670822 bytes to /content/PS3_Attention_Please_2024_ID_310320650.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbconvert"
      ],
      "metadata": {
        "id": "BdrTqlgcGLbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "531b7dcb-9942-4b4d-f71e-975aabe14c9d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (7.16.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (3.1.5)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (3.1.1)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (5.10.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from nbconvert) (24.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (2.18.0)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (5.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert) (1.4.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.7->nbconvert) (4.3.6)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from nbclient>=0.5.0->nbconvert) (6.1.12)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert) (4.23.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert) (2.6)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.22.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (24.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.8.2)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat>=5.7->nbconvert) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert -- to html '/content/drive/MyDrive/Statistics\\ Masters/Adv.\\ computational learning and data analysis/Problem\\ Set\\ 3/PS3_Attention_Please_2024_ID_310320650.ipynb'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg0SsjU_3FQM",
        "outputId": "a4d03b92-e9e8-48d9-ac84-2fad36e37b7b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] WARNING | pattern 'to' matched no files\n",
            "[NbConvertApp] WARNING | pattern 'html' matched no files\n",
            "[NbConvertApp] WARNING | pattern '/content/drive/MyDrive/Statistics\\\\ Masters/Adv.\\\\ computational learning and data analysis/Problem\\\\ Set\\\\ 3/PS3_Attention_Please_2024_ID_310320650.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--coalesce-streams\n",
            "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    Overwrite base name use for output files.\n",
            "                Supports pattern replacements '{notebook_name}'.\n",
            "    Default: '{notebook_name}'\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/Statistics\\ Masters/Adv.\\ computational learning and data analysis/Problem\\ Set\\ 3/PS3_Attention_Please_2024_ID_310320650.ipynb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "wak5lQXa3Pk8",
        "outputId": "b2d0c117-406b-45ef-b35b-8664e8aa48c4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Cannot find file: /content/drive/MyDrive/Statistics\\ Masters/Adv.\\ computational\\ learning\\ and\\ data\\ analysis/Problem\\ Set\\ 3/PS3_Attention_Please_2024_ID_310320650.ipynb",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-509cc19ed931>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Statistics\\ Masters/Adv.\\ computational\\ learning\\ and\\ data\\ analysis/Problem\\ Set\\ 3/PS3_Attention_Please_2024_ID_310320650.ipynb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/drive/MyDrive/Statistics\\ Masters/Adv.\\ computational\\ learning\\ and\\ data\\ analysis/Problem\\ Set\\ 3/PS3_Attention_Please_2024_ID_310320650.ipynb"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h4ount423Y3z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}